{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572ef0f7",
   "metadata": {},
   "source": [
    "## Step 1: Setup Google Colab Environment\n",
    "\n",
    "This installs all required libraries and downloads your dataset from Kaggle Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q scikit-image scikit-learn opencv-python albumentations tensorflow keras-applications tensorboard kagglehub\n",
    "\n",
    "print(\"‚úì Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec590bb",
   "metadata": {},
   "source": [
    "## Step 2: Data Augmentation Strategy\n",
    "\n",
    "### Why Augmentation?\n",
    "With limited samples, we artificially create variations:\n",
    "- **Rotation**: Fabric rotated at different angles\n",
    "- **Scaling**: Zoomed in/out (simulates different microscope magnifications)\n",
    "- **Elastic Deformation**: Stretches fabric slightly (realistic)\n",
    "- **Brightness/Contrast**: Lighting variations\n",
    "- **Noise**: Camera/sensor noise\n",
    "\n",
    "This trains the model to be **robust** - works with imperfect real-world images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd46a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Augmentation library\n",
    "import albumentations as A\n",
    "from albumentations import DualTransform\n",
    "\n",
    "class TextileDataAugmentor:\n",
    "    \"\"\"\n",
    "    Advanced augmentation designed for fabric microscopy images.\n",
    "    \n",
    "    Why these specific augmentations?\n",
    "    - Rotations: Fabric can be scanned at any angle\n",
    "    - Scale: Simulates different zoom levels\n",
    "    - Elastic: Realistic fabric deformation\n",
    "    - Noise: Camera sensor imperfections\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=42):\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Define augmentation pipeline\n",
    "        self.augmenter = A.Compose([\n",
    "            # Rotation: fabric can be oriented any direction\n",
    "            A.Rotate(limit=180, p=0.8, border_mode=cv2.BORDER_REFLECT),\n",
    "            \n",
    "            # Scale: simulates zoom variations\n",
    "            A.RandomScale(scale_limit=0.2, p=0.7),\n",
    "            \n",
    "            # Elastic deformation: realistic fabric stretching\n",
    "            A.ElasticTransform(\n",
    "                alpha=50, sigma=5, alpha_affine=20,\n",
    "                p=0.6, border_mode=cv2.BORDER_REFLECT\n",
    "            ),\n",
    "            \n",
    "            # Grid distortion: simulates wrinkles/folds\n",
    "            A.GridDistortion(\n",
    "                num_steps=5, distort_limit=0.15,\n",
    "                p=0.5, border_mode=cv2.BORDER_REFLECT\n",
    "            ),\n",
    "            \n",
    "            # Brightness/Contrast: lighting variations\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2, contrast_limit=0.2, p=0.7\n",
    "            ),\n",
    "            \n",
    "            # Gaussian blur: camera focus variations\n",
    "            A.GaussBlur(blur_limit=3, p=0.3),\n",
    "            \n",
    "            # Gaussian noise: sensor noise\n",
    "            A.GaussNoise(p=0.4),\n",
    "        ])\n",
    "    \n",
    "    def augment(self, image: np.ndarray, num_augmentations: int = 5) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        Create multiple augmented versions of image.\n",
    "        \n",
    "        Args:\n",
    "            image: Input fabric image (H, W, C)\n",
    "            num_augmentations: How many variations to create\n",
    "        \n",
    "        Returns:\n",
    "            List of augmented images\n",
    "        \"\"\"\n",
    "        augmented = [image]  # Include original\n",
    "        \n",
    "        for _ in range(num_augmentations):\n",
    "            aug_image = self.augmenter(image=image)['image']\n",
    "            augmented.append(aug_image)\n",
    "        \n",
    "        return augmented\n",
    "\n",
    "print(\"‚úì Data augmentation module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77fbab",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction - The Heart of the Pipeline\n",
    "\n",
    "### Feature Types Explained:\n",
    "\n",
    "**GLCM Features** (Gray Level Co-occurrence Matrix)\n",
    "- Measures pixel relationships in different directions\n",
    "- **Contrast**: Difference in pixel values ‚Üí weave tightness\n",
    "- **Homogeneity**: Similar pixels nearby ‚Üí dense/tight weave\n",
    "- **Energy**: Pixel repeatability ‚Üí regular pattern strength\n",
    "- **Correlation**: Pixel dependency ‚Üí weave structure\n",
    "\n",
    "**LBP Features** (Local Binary Pattern)\n",
    "- Looks at 8 neighbors of each pixel\n",
    "- Creates histogram of patterns ‚Üí yarn texture\n",
    "\n",
    "**Textile-Specific Features**\n",
    "- **Warp Density**: Threads per inch in vertical direction\n",
    "- **Weft Density**: Threads per inch in horizontal direction\n",
    "- **Yarn Diameter**: Estimated from image\n",
    "- **Density**: (Warp + Weft) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from scipy import ndimage\n",
    "\n",
    "class TextileFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract textile-specific features from fabric images.\n",
    "    \n",
    "    This module is the CORE of our GSM prediction.\n",
    "    Features directly relate to:\n",
    "    - Fabric structure (weave type)\n",
    "    - Yarn properties (thickness, material)\n",
    "    - Surface density (GSM indicator)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = None\n",
    "    \n",
    "    def extract_glcm_features(self, gray_image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract GLCM texture features.\n",
    "        \n",
    "        What it does:\n",
    "        - Analyzes pixel co-occurrence at different distances/angles\n",
    "        - Returns 4 metrics √ó 2 distances √ó 4 angles = 32 features\n",
    "        \"\"\"\n",
    "        # Quantize to 32 levels (reduces computation)\n",
    "        gray_quant = (gray_image / 8).astype(np.uint8)\n",
    "        \n",
    "        # Compute GLCM at multiple distances and angles\n",
    "        glcm = graycomatrix(\n",
    "            gray_quant,\n",
    "            distances=[1, 3],  # Pixel distances to consider\n",
    "            angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],  # 0¬∞, 45¬∞, 90¬∞, 135¬∞\n",
    "            levels=32,\n",
    "            symmetric=True,\n",
    "            normed=True\n",
    "        )\n",
    "        \n",
    "        # Extract metrics\n",
    "        features = []\n",
    "        for metric in ['contrast', 'homogeneity', 'energy', 'correlation']:\n",
    "            props = graycoprops(glcm, metric)\n",
    "            features.extend(props.flatten())\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_lbp_features(self, gray_image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract Local Binary Pattern features.\n",
    "        \n",
    "        What it does:\n",
    "        - Looks at 8 neighbors around each pixel\n",
    "        - Creates histogram of micro-patterns\n",
    "        - Returns 59 bins = 59 features\n",
    "        \"\"\"\n",
    "        # Compute LBP\n",
    "        lbp = feature.local_binary_pattern(\n",
    "            gray_image,\n",
    "            P=8,  # 8 neighbors\n",
    "            R=3,  # radius 3 pixels\n",
    "            method='uniform'\n",
    "        )\n",
    "        \n",
    "        # Create histogram\n",
    "        hist, _ = np.histogram(\n",
    "            lbp.ravel(),\n",
    "            bins=np.arange(0, 60),  # 59 unique uniform patterns\n",
    "            range=(0, 59)\n",
    "        )\n",
    "        \n",
    "        # Normalize histogram\n",
    "        return hist.astype(float) / hist.sum()\n",
    "    \n",
    "    def estimate_density_features(self, gray_image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Estimate yarn/warp/weft density features.\n",
    "        \n",
    "        What it does:\n",
    "        - Analyzes horizontal/vertical thread patterns\n",
    "        - Estimates yarn diameter\n",
    "        - Calculates thread density\n",
    "        Returns: [warp_density, weft_density, yarn_diameter, total_density]\n",
    "        \"\"\"\n",
    "        h, w = gray_image.shape\n",
    "        \n",
    "        # Detect threads using edge detection\n",
    "        edges = cv2.Canny(gray_image, 100, 200)\n",
    "        \n",
    "        # Count vertical threads (warp) - count transitions in columns\n",
    "        vertical_sum = edges.sum(axis=0)\n",
    "        warp_density = float(np.count_nonzero(vertical_sum > 0) / w)\n",
    "        \n",
    "        # Count horizontal threads (weft) - count transitions in rows\n",
    "        horizontal_sum = edges.sum(axis=1)\n",
    "        weft_density = float(np.count_nonzero(horizontal_sum > 0) / h)\n",
    "        \n",
    "        # Estimate yarn diameter from edge thickness\n",
    "        yarn_diameter = float(np.mean(np.where(edges > 0)[0])) / h if np.any(edges) else 0.1\n",
    "        \n",
    "        # Total density (indicates GSM!)\n",
    "        total_density = (warp_density + weft_density) / 2.0\n",
    "        \n",
    "        return np.array([\n",
    "            warp_density,\n",
    "            weft_density,\n",
    "            yarn_diameter,\n",
    "            total_density\n",
    "        ])\n",
    "    \n",
    "    def extract_all_features(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract all textile features from single image.\n",
    "        \n",
    "        Total: 32 GLCM + 59 LBP + 4 Density = 95 features\n",
    "        \"\"\"\n",
    "        # Convert to grayscale\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            gray = image\n",
    "        \n",
    "        # Extract features\n",
    "        glcm_feat = self.extract_glcm_features(gray)\n",
    "        lbp_feat = self.extract_lbp_features(gray)\n",
    "        density_feat = self.estimate_density_features(gray)\n",
    "        \n",
    "        # Combine all features\n",
    "        return np.concatenate([glcm_feat, lbp_feat, density_feat])\n",
    "\n",
    "print(\"‚úì Textile feature extractor loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb6266",
   "metadata": {},
   "source": [
    "## Step 4: Deep Learning Features (Transfer Learning)\n",
    "\n",
    "### What is Transfer Learning?\n",
    "We use a **pretrained neural network** (MobileNetV3) that was trained on millions of images.\n",
    "\n",
    "**Why this is powerful:**\n",
    "- Already learned to detect edges, textures, patterns\n",
    "- We \"reuse\" this knowledge instead of starting from scratch\n",
    "- With few fabric samples, this prevents overfitting\n",
    "\n",
    "**MobileNetV3:**\n",
    "- Lightweight (runs on phones!)\n",
    "- Efficient for edge devices (Raspberry Pi)\n",
    "- Returns 1280 features per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow for neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "class DeepFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract features using MobileNetV3 (pretrained neural network).\n",
    "    \n",
    "    How it works:\n",
    "    1. Image goes through neural network\n",
    "    2. We extract features from second-to-last layer\n",
    "    3. These features capture high-level patterns\n",
    "    4. Returns 1280 features per image\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(224, 224, 3)):\n",
    "        # Load pretrained MobileNetV3\n",
    "        self.model = MobileNetV3Small(\n",
    "            input_shape=input_shape,\n",
    "            include_top=False,  # Remove classification layer\n",
    "            weights='imagenet',  # Use pretrained weights\n",
    "            pooling='avg'  # Global average pooling\n",
    "        )\n",
    "        \n",
    "        # Freeze weights (don't retrain)\n",
    "        self.model.trainable = False\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "    \n",
    "    def extract(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract deep features from image.\n",
    "        \n",
    "        Args:\n",
    "            image: Image array (H, W, 3)\n",
    "        \n",
    "        Returns:\n",
    "            Feature vector (1280,)\n",
    "        \"\"\"\n",
    "        # Resize to model input size\n",
    "        img_resized = cv2.resize(image, (self.input_shape[0], self.input_shape[1]))\n",
    "        \n",
    "        # Preprocess for ImageNet\n",
    "        img_array = np.expand_dims(img_resized, axis=0)  # Add batch dimension\n",
    "        img_array = preprocess_input(img_array)  # Normalize\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.model.predict(img_array, verbose=0)\n",
    "        \n",
    "        return features.flatten()\n",
    "\n",
    "print(\"‚úì Deep feature extractor (MobileNetV3) loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02530f2d",
   "metadata": {},
   "source": [
    "## Step 5: Load Dataset and Prepare Data\n",
    "\n",
    "### Steps:\n",
    "1. Download dataset from Kaggle Hub\n",
    "2. Load images and GSM labels from Excel\n",
    "3. Augment dataset (create multiple versions)\n",
    "4. Extract features for each image\n",
    "5. Normalize features (critical for regression!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd779d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "# Download latest version of FabricNet dataset\n",
    "print(\"üì• Downloading FabricNet dataset from Kaggle Hub...\")\n",
    "path = kagglehub.dataset_download(\"acseckn/fabricnet\")\n",
    "\n",
    "print(f\"‚úì Dataset downloaded successfully!\")\n",
    "print(f\"  Path: {path}\")\n",
    "print(f\"  Contents: {list(Path(path).glob('*'))[:5]}\")\n",
    "\n",
    "DATASET_PATH = path  # Use downloaded path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70460df",
   "metadata": {},
   "source": [
    "## Step 6: Complete Data Pipeline\n",
    "\n",
    "This combines everything:\n",
    "- Loads images\n",
    "- Applies data augmentation\n",
    "- Extracts features\n",
    "- Normalizes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"\n",
    "    Complete data processing pipeline.\n",
    "    \n",
    "    Flow:\n",
    "    Raw Image ‚Üí Augmentation ‚Üí Feature Extraction ‚Üí Normalization ‚Üí Training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path: str, excel_file: str = \"FabricNet_parameters.xlsx\"):\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.excel_file = self.dataset_path / excel_file\n",
    "        \n",
    "        # Initialize feature extractors\n",
    "        self.textile_extractor = TextileFeatureExtractor()\n",
    "        self.deep_extractor = DeepFeatureExtractor()\n",
    "        self.augmentor = TextileDataAugmentor()\n",
    "        \n",
    "        # Load labels\n",
    "        self.labels_df = self._load_labels()\n",
    "    \n",
    "    def _load_labels(self) -> pd.DataFrame:\n",
    "        \"\"\"Load GSM labels from Excel file.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_excel(self.excel_file)\n",
    "            print(f\"‚úì Loaded {len(df)} samples from Excel\")\n",
    "            print(f\"  Columns: {list(df.columns)}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error loading Excel: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def load_image(self, image_name: str) -> np.ndarray:\n",
    "        \"\"\"Load single image.\"\"\"\n",
    "        img_path = self.dataset_path / image_name\n",
    "        if not img_path.exists():\n",
    "            return None\n",
    "        \n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "    \n",
    "    def process_image(self, image: np.ndarray, num_augmentations: int = 4) -> Tuple[list, int]:\n",
    "        \"\"\"\n",
    "        Process single image:\n",
    "        1. Augment (create variations)\n",
    "        2. Extract textile features\n",
    "        3. Extract deep features\n",
    "        4. Combine features\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        # Step 1: Augment image\n",
    "        augmented_images = self.augmentor.augment(image, num_augmentations)\n",
    "        \n",
    "        # Step 2 & 3: Extract features from each augmented version\n",
    "        for aug_img in augmented_images:\n",
    "            # Textile features (95 features)\n",
    "            textile_feat = self.textile_extractor.extract_all_features(aug_img)\n",
    "            \n",
    "            # Deep features (1280 features)\n",
    "            deep_feat = self.deep_extractor.extract(aug_img)\n",
    "            \n",
    "            # Combine (1375 features total)\n",
    "            combined = np.concatenate([textile_feat, deep_feat])\n",
    "            features_list.append(combined)\n",
    "        \n",
    "        return features_list, len(augmented_images)\n",
    "    \n",
    "    def prepare_dataset(\n",
    "        self,\n",
    "        num_augmentations: int = 4,\n",
    "        gsm_column: str = \"Specific Mass\"\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Prepare complete dataset with augmentation.\n",
    "        \n",
    "        Returns:\n",
    "            X: Feature matrix (N_samples, 1375)\n",
    "            y: GSM labels (N_samples,)\n",
    "        \"\"\"\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        \n",
    "        if self.labels_df is None:\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"\\nüìä Processing {len(self.labels_df)} samples with {num_augmentations+1} augmentations...\")\n",
    "        \n",
    "        for idx, row in self.labels_df.iterrows():\n",
    "            # Get image filename\n",
    "            if 'image_filename' in row:\n",
    "                image_name = row['image_filename']\n",
    "            else:\n",
    "                image_name = f\"W{row.get('Image id', idx):03d}.jpg\"\n",
    "            \n",
    "            # Load image\n",
    "            image = self.load_image(image_name)\n",
    "            if image is None:\n",
    "                print(f\"  ‚ö†Ô∏è Skipped {image_name} (not found)\")\n",
    "                continue\n",
    "            \n",
    "            # Get GSM label\n",
    "            gsm = float(row[gsm_column])\n",
    "            \n",
    "            # Process image (augment + extract features)\n",
    "            try:\n",
    "                features_list, aug_count = self.process_image(image, num_augmentations)\n",
    "                \n",
    "                # Add features and labels\n",
    "                all_features.extend(features_list)\n",
    "                all_labels.extend([gsm] * aug_count)\n",
    "                \n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    print(f\"  ‚úì Processed {idx+1}/{len(self.labels_df)} images\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚úó Error processing {image_name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(all_features)\n",
    "        y = np.array(all_labels)\n",
    "        \n",
    "        print(f\"\\n‚úì Dataset prepared: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        print(f\"  GSM range: {y.min():.2f} - {y.max():.2f} g/m¬≤\")\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "print(\"‚úì Data pipeline class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383fb7b",
   "metadata": {},
   "source": [
    "## Step 7: Feature Normalization\n",
    "\n",
    "### Why Normalize?\n",
    "Features have different scales:\n",
    "- GLCM: 0-1\n",
    "- LBP: 0-1\n",
    "- Deep features: very large numbers\n",
    "\n",
    "Normalization **centers and scales** all features to mean=0, std=1.\n",
    "\n",
    "This helps regression algorithms work better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79108193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FeatureNormalizer:\n",
    "    \"\"\"\n",
    "    Normalize features to zero mean and unit variance.\n",
    "    \n",
    "    Formula: x_normalized = (x - mean) / std\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X: np.ndarray):\n",
    "        \"\"\"Learn mean and std from training data.\"\"\"\n",
    "        self.scaler.fit(X)\n",
    "        self.is_fitted = True\n",
    "        print(f\"‚úì Scaler fitted on {X.shape[0]} samples\")\n",
    "    \n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply normalization.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Scaler not fitted yet. Call fit() first.\")\n",
    "        return self.scaler.transform(X)\n",
    "    \n",
    "    def fit_transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Fit and transform in one step.\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "print(\"‚úì Feature normalizer loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a692f8d",
   "metadata": {},
   "source": [
    "## Step 8: Build and Train Regression Models\n",
    "\n",
    "### Why Multiple Models?\n",
    "We train 2 models and compare:\n",
    "\n",
    "1. **Random Forest**\n",
    "   - Many decision trees voting together\n",
    "   - Robust, works well with mixed features\n",
    "   - Fast prediction\n",
    "\n",
    "2. **Gradient Boosting**\n",
    "   - Sequential trees learning from mistakes\n",
    "   - Usually more accurate\n",
    "   - But can overfit\n",
    "\n",
    "### Model Evaluation Metrics:\n",
    "- **MAE** (Mean Absolute Error): Average prediction error in g/m¬≤\n",
    "- **RMSE** (Root Mean Squared Error): Penalizes large errors\n",
    "- **R¬≤** (Coefficient of Determination): Explains how much variance (0-1, higher better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "\n",
    "class GSMRegressionModels:\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple regression models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # Define models\n",
    "        self.models = {\n",
    "            'Random Forest': RandomForestRegressor(\n",
    "                n_estimators=200,          # 200 trees\n",
    "                max_depth=20,              # Tree depth\n",
    "                min_samples_split=5,       # Min samples to split\n",
    "                min_samples_leaf=2,        # Min samples in leaf\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,                 # Use all CPU cores\n",
    "                verbose=0\n",
    "            ),\n",
    "            'Gradient Boosting': GradientBoostingRegressor(\n",
    "                n_estimators=200,          # 200 boosting stages\n",
    "                learning_rate=0.1,         # Learning rate (lower = more careful)\n",
    "                max_depth=5,               # Tree depth (keep small)\n",
    "                min_samples_split=5,       # Min samples to split\n",
    "                min_samples_leaf=2,        # Min samples in leaf\n",
    "                subsample=0.8,             # Use 80% of samples per iteration\n",
    "                random_state=random_state,\n",
    "                verbose=0\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        self.trained_models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def train(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_test: np.ndarray = None,\n",
    "        y_test: np.ndarray = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train all models.\n",
    "        \"\"\"\n",
    "        print(\"\\nüéØ Training regression models...\\n\")\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"Training {model_name}...\")\n",
    "            \n",
    "            # Train\n",
    "            model.fit(X_train, y_train)\n",
    "            self.trained_models[model_name] = model\n",
    "            \n",
    "            # Evaluate on training set\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "            train_r2 = r2_score(y_train, y_pred_train)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            if X_test is not None:\n",
    "                y_pred_test = model.predict(X_test)\n",
    "                test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "                test_r2 = r2_score(y_test, y_pred_test)\n",
    "            else:\n",
    "                test_mae = test_rmse = test_r2 = None\n",
    "            \n",
    "            # Store results\n",
    "            self.results[model_name] = {\n",
    "                'train_mae': train_mae,\n",
    "                'train_rmse': train_rmse,\n",
    "                'train_r2': train_r2,\n",
    "                'test_mae': test_mae,\n",
    "                'test_rmse': test_rmse,\n",
    "                'test_r2': test_r2,\n",
    "                'predictions': y_pred_test if X_test is not None else None,\n",
    "                'actual': y_test\n",
    "            }\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"  ‚úì Training - MAE: {train_mae:.2f}, RMSE: {train_rmse:.2f}, R¬≤: {train_r2:.4f}\")\n",
    "            if X_test is not None:\n",
    "                print(f\"  ‚úì Testing  - MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, R¬≤: {test_r2:.4f}\")\n",
    "            print()\n",
    "    \n",
    "    def get_best_model(self):\n",
    "        \"\"\"Get best model based on test R¬≤ score.\"\"\"\n",
    "        best_name = max(\n",
    "            self.results.keys(),\n",
    "            key=lambda x: self.results[x]['test_r2'] if self.results[x]['test_r2'] is not None else self.results[x]['train_r2']\n",
    "        )\n",
    "        return best_name, self.trained_models[best_name]\n",
    "\n",
    "print(\"‚úì Regression model classes loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006931b",
   "metadata": {},
   "source": [
    "## Step 9: Execute Complete Training Pipeline\n",
    "\n",
    "This is where everything comes together!\n",
    "\n",
    "The dataset has been automatically downloaded from Kaggle Hub above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline with Kaggle downloaded dataset\n",
    "print(\"üöÄ Starting complete training pipeline...\\n\")\n",
    "\n",
    "pipeline = DataPipeline(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04795040",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Results\n",
    "\n",
    "Let's see how well our model performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (model_name, results) in enumerate(trainer.results.items()):\n",
    "    if results['predictions'] is not None:\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Scatter plot: Actual vs Predicted\n",
    "        ax.scatter(\n",
    "            results['actual'],\n",
    "            results['predictions'],\n",
    "            alpha=0.6, s=50\n",
    "        )\n",
    "        \n",
    "        # Perfect prediction line\n",
    "        min_val = min(results['actual'].min(), results['predictions'].min())\n",
    "        max_val = max(results['actual'].max(), results['predictions'].max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect', lw=2)\n",
    "        \n",
    "        ax.set_xlabel('Actual GSM (g/m¬≤)', fontsize=11)\n",
    "        ax.set_ylabel('Predicted GSM (g/m¬≤)', fontsize=11)\n",
    "        ax.set_title(f'{model_name}\\nR¬≤ = {results[\"test_r2\"]:.4f}', fontsize=12, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Model Performance: Actual vs Predicted GSM', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualization saved as /content/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce78f08",
   "metadata": {},
   "source": [
    "## Step 11: Feature Importance Analysis\n",
    "\n",
    "Which features are most important for predicting GSM?\n",
    "\n",
    "This helps understand what the model learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae19cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from Random Forest\n",
    "if 'Random Forest' in trainer.trained_models:\n",
    "    rf_model = trainer.trained_models['Random Forest']\n",
    "    importances = rf_model.feature_importances_\n",
    "    \n",
    "    # Get top features\n",
    "    top_n = 15\n",
    "    top_indices = np.argsort(importances)[-top_n:][::-1]\n",
    "    top_importances = importances[top_indices]\n",
    "    \n",
    "    # Feature names\n",
    "    feature_names = []\n",
    "    feature_names.extend([f'GLCM_{i}' for i in range(32)])  # GLCM features\n",
    "    feature_names.extend([f'LBP_{i}' for i in range(59)])    # LBP features\n",
    "    feature_names.extend(['Warp_Density', 'Weft_Density', 'Yarn_Diameter', 'Total_Density'])  # Density\n",
    "    feature_names.extend([f'DeepFeat_{i}' for i in range(1280)])  # Deep features\n",
    "    \n",
    "    top_names = [feature_names[i] for i in top_indices]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(top_names)), top_importances, color='steelblue')\n",
    "    plt.yticks(range(len(top_names)), top_names)\n",
    "    plt.xlabel('Feature Importance', fontsize=12)\n",
    "    plt.title('Top 15 Most Important Features for GSM Prediction', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Feature importance visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef81ad2",
   "metadata": {},
   "source": [
    "## Step 12: Summary and Next Steps\n",
    "\n",
    "### What We Did:\n",
    "‚úÖ **Data Augmentation**: Created 5x more data from original images\n",
    "‚úÖ **Feature Engineering**: Extracted 1375 features per image (textile + deep)\n",
    "‚úÖ **Normalization**: Scaled features to comparable ranges\n",
    "‚úÖ **Model Training**: Trained Random Forest & Gradient Boosting\n",
    "‚úÖ **Evaluation**: Measured MAE, RMSE, R¬≤\n",
    "‚úÖ **Feature Analysis**: Identified important features\n",
    "\n",
    "### Results Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive summary\n",
    "print(\"=\"*60)\n",
    "print(\"üéâ TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(y)}\")\n",
    "print(f\"  Training samples: {len(y_train)}\")\n",
    "print(f\"  Testing samples: {len(y_test)}\")\n",
    "print(f\"  GSM range: {y.min():.2f} - {y.max():.2f} g/m¬≤\")\n",
    "print(f\"  GSM mean: {y.mean():.2f} g/m¬≤\")\n",
    "\n",
    "print(f\"\\nüî¢ Feature Engineering:\")\n",
    "print(f\"  GLCM features: 32\")\n",
    "print(f\"  LBP features: 59\")\n",
    "print(f\"  Textile-specific features: 4 (warp, weft, yarn, density)\")\n",
    "print(f\"  Deep learning features: 1280 (MobileNetV3)\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüéØ Model Performance Comparison:\")\n",
    "print(f\"\\n{'Model':<20} {'MAE (g/m¬≤)':<15} {'RMSE (g/m¬≤)':<15} {'R¬≤ Score':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for model_name, results in trainer.results.items():\n",
    "    mae = results['test_mae']\n",
    "    rmse = results['test_rmse']\n",
    "    r2 = results['test_r2']\n",
    "    print(f\"{model_name:<20} {mae:>14.2f} {rmse:>14.2f} {r2:>14.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_name}\")\n",
    "print(f\"  Accuracy: {trainer.results[best_name]['test_r2']:.4f} (explains {trainer.results[best_name]['test_r2']*100:.1f}% of variance)\")\n",
    "print(f\"  Average Error: ¬±{trainer.results[best_name]['test_mae']:.2f} g/m¬≤\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(f\"  ‚úì /content/models/feature_scaler.pkl\")\n",
    "print(f\"  ‚úì /content/models/gsm_model_{best_name.replace(' ', '_')}.pkl\")\n",
    "print(f\"  ‚úì /content/model_comparison.png\")\n",
    "print(f\"  ‚úì /content/feature_importance.png\")\n",
    "\n",
    "print(f\"\\nüì• Download these files to your local machine!\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9484152",
   "metadata": {},
   "source": [
    "## Advanced: Hyperparameter Tuning (Optional)\n",
    "\n",
    "To improve model accuracy further, tune hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Hyperparameter tuning using RandomizedSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# This is optional - only run if you want better accuracy\n",
    "# Warning: This takes longer to train!\n",
    "\n",
    "print(\"\\nüîç Hyperparameter Tuning (Optional)\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nThis searches for best hyperparameters.\")\n",
    "print(\"Takes ~5-10 minutes but can improve accuracy.\")\n",
    "print(\"\\nUncomment code below to enable:\")\n",
    "\n",
    "# param_dist = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [15, 20, 25, 30],\n",
    "#     'min_samples_split': [3, 5, 7],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "#\n",
    "# rf_search = RandomizedSearchCV(\n",
    "#     RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "#     param_dist,\n",
    "#     n_iter=20,  # Try 20 random combinations\n",
    "#     cv=5,  # 5-fold cross validation\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "#\n",
    "# print(\"\\nSearching for best parameters...\")\n",
    "# rf_search.fit(X_train, y_train)\n",
    "#\n",
    "# print(f\"\\nBest parameters: {rf_search.best_params_}\")\n",
    "# print(f\"Best CV score: {rf_search.best_score_:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
