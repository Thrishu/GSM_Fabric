{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1668f855",
   "metadata": {},
   "source": [
    "# üßµ GSM Prediction from Fabric Microscopy Images\n",
    "\n",
    "## Hybrid Deep Learning Approach (No Augmentation)\n",
    "\n",
    "**Research Objective:** Develop an accurate GSM prediction model using:\n",
    "- Pre-trained CNN features (EfficientNet-B3)\n",
    "- 64 engineered fabric-specific features\n",
    "\n",
    "**Target Accuracy:** ¬±5 GSM prediction error\n",
    "\n",
    "**Dataset:** 177 original microscopy images with extracted features (70% train, 15% val, 15% test)\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start (Google Colab)\n",
    "1. Upload `split_feature_dataset` folder to Google Drive\n",
    "2. Mount Drive and set `DATASET_PATH` below\n",
    "3. Run all cells sequentially\n",
    "4. Model will be saved to Drive after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48842902",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e4e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"\\n‚úÖ Environment configured with seed:\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612150c",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06df036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    BASE_PATH = '/content/drive/MyDrive/fabric_gsm_pipeline'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    BASE_PATH = 'data'\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_PATH = f\"{BASE_PATH}/split_feature_dataset\"\n",
    "TRAIN_IMAGES = f\"{DATASET_PATH}/train/images\"\n",
    "VAL_IMAGES = f\"{DATASET_PATH}/val/images\"\n",
    "TEST_IMAGES = f\"{DATASET_PATH}/test/images\"\n",
    "TRAIN_CSV = f\"{DATASET_PATH}/train/dataset_train.csv\"\n",
    "VAL_CSV = f\"{DATASET_PATH}/val/dataset_val.csv\"\n",
    "TEST_CSV = f\"{DATASET_PATH}/test/dataset_test.csv\"\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9e336",
   "metadata": {},
   "source": [
    "## 3. Import Libraries & Visualization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399905e5",
   "metadata": {},
   "source": [
    "## 4. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val = pd.read_csv(VAL_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train samples: {len(df_train)}\")\n",
    "print(f\"Val samples:   {len(df_val)}\")\n",
    "print(f\"Test samples:  {len(df_test)}\")\n",
    "print(f\"Total:         {len(df_train) + len(df_val) + len(df_test)}\")\n",
    "\n",
    "# Feature columns (exclude metadata)\n",
    "meta_cols = ['image_name', 'gsm', 'source']\n",
    "feature_cols = [col for col in df_train.columns if col not in meta_cols]\n",
    "\n",
    "print(f\"\\nüî¨ Extracted features: {len(feature_cols)}\")\n",
    "print(f\"Feature names: {feature_cols[:5]}... (showing first 5)\")\n",
    "\n",
    "# GSM distribution\n",
    "print(\"\\nüìä GSM Distribution:\")\n",
    "print(f\"Train - Mean: {df_train['gsm'].mean():.2f}, Std: {df_train['gsm'].std():.2f}, Range: [{df_train['gsm'].min():.0f}, {df_train['gsm'].max():.0f}]\")\n",
    "print(f\"Val   - Mean: {df_val['gsm'].mean():.2f}, Std: {df_val['gsm'].std():.2f}, Range: [{df_val['gsm'].min():.0f}, {df_val['gsm'].max():.0f}]\")\n",
    "print(f\"Test  - Mean: {df_test['gsm'].mean():.2f}, Std: {df_test['gsm'].std():.2f}, Range: [{df_test['gsm'].min():.0f}, {df_test['gsm'].max():.0f}]\")\n",
    "\n",
    "# Visualize GSM distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, (df, name) in enumerate([(df_train, 'Train'), (df_val, 'Val'), (df_test, 'Test')]):\n",
    "    axes[i].hist(df['gsm'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'{name} GSM Distribution')\n",
    "    axes[i].set_xlabel('GSM (g/m¬≤)')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].axvline(df['gsm'].mean(), color='red', linestyle='--', label=f\"Mean: {df['gsm'].mean():.1f}\")\n",
    "    axes[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dataset loaded and explored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8089d4",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"üîß Preprocessing extracted features...\")\n",
    "\n",
    "# Fill NaN with median for each feature\n",
    "for col in feature_cols:\n",
    "    if df_train[col].isna().any():\n",
    "        median_val = df_train[col].median()\n",
    "        df_train[col].fillna(median_val, inplace=True)\n",
    "        df_val[col].fillna(median_val, inplace=True)\n",
    "        df_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Remove features with zero variance\n",
    "zero_var_cols = []\n",
    "for col in feature_cols:\n",
    "    if df_train[col].std() == 0:\n",
    "        zero_var_cols.append(col)\n",
    "\n",
    "if zero_var_cols:\n",
    "    print(f\"Removing {len(zero_var_cols)} zero-variance features: {zero_var_cols}\")\n",
    "    feature_cols = [col for col in feature_cols if col not in zero_var_cols]\n",
    "\n",
    "# Standardize features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[feature_cols])\n",
    "X_val_scaled = scaler.transform(df_val[feature_cols])\n",
    "X_test_scaled = scaler.transform(df_test[feature_cols])\n",
    "\n",
    "print(f\"\\n‚úÖ Features preprocessed: {len(feature_cols)} features\")\n",
    "print(f\"Scaled shapes - Train: {X_train_scaled.shape}, Val: {X_val_scaled.shape}, Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4c2ca",
   "metadata": {},
   "source": [
    "## 6. Custom Dataset Class (Hybrid: Images + Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FabricGSMDataset(Dataset):\n",
    "    \"\"\"Dataset combining images and engineered features for GSM prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, features_array, images_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.features = features_array\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.df.iloc[idx]['image_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get engineered features\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        \n",
    "        # Get target GSM\n",
    "        gsm = torch.tensor(self.df.iloc[idx]['gsm'], dtype=torch.float32)\n",
    "        \n",
    "        return image, features, gsm\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FabricGSMDataset(df_train, X_train_scaled, TRAIN_IMAGES, transform=train_transform)\n",
    "val_dataset = FabricGSMDataset(df_val, X_val_scaled, VAL_IMAGES, transform=val_test_transform)\n",
    "test_dataset = FabricGSMDataset(df_test, X_test_scaled, TEST_IMAGES, transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 16  # Smaller batch size for smaller dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"‚úÖ Datasets created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d11dc2",
   "metadata": {},
   "source": [
    "## 7. Hybrid Deep Learning Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fdea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGSMPredictor(nn.Module):\n",
    "    \"\"\"Hybrid model combining EfficientNet-B3 CNN with engineered fabric features.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, dropout=0.5):\n",
    "        super(HybridGSMPredictor, self).__init__()\n",
    "        \n",
    "        # Pre-trained EfficientNet-B3 backbone\n",
    "        efficientnet = models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Freeze early layers (feature extraction)\n",
    "        for param in list(efficientnet.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Remove classifier head\n",
    "        self.cnn_features = nn.Sequential(*list(efficientnet.children())[:-1])\n",
    "        cnn_feature_size = 1536  # EfficientNet-B3 output\n",
    "        \n",
    "        # Feature processing branch\n",
    "        self.feature_branch = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout/2)\n",
    "        )\n",
    "        \n",
    "        # Fusion and prediction head\n",
    "        combined_size = cnn_feature_size + 128\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(combined_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, features):\n",
    "        # Extract CNN features\n",
    "        cnn_out = self.cnn_features(images)\n",
    "        cnn_out = torch.flatten(cnn_out, 1)\n",
    "        \n",
    "        # Process engineered features\n",
    "        feat_out = self.feature_branch(features)\n",
    "        \n",
    "        # Concatenate and predict\n",
    "        combined = torch.cat([cnn_out, feat_out], dim=1)\n",
    "        output = self.fusion(combined)\n",
    "        \n",
    "        return output.squeeze()\n",
    "\n",
    "# Initialize model\n",
    "model = HybridGSMPredictor(num_features=len(feature_cols), dropout=0.5)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üß† MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Backbone: EfficientNet-B3 (ImageNet pretrained)\")\n",
    "print(f\"Input features: {len(feature_cols)} fabric-specific features\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aeae9f",
   "metadata": {},
   "source": [
    "## 8. Training Configuration & Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 150  # More epochs for smaller dataset\n",
    "INITIAL_LR = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 20  # Increased patience for smaller dataset\n",
    "\n",
    "# Custom loss function\n",
    "class HuberLoss(nn.Module):\n",
    "    \"\"\"Huber loss - robust to outliers.\"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        error = pred - target\n",
    "        abs_error = torch.abs(error)\n",
    "        quadratic = torch.clamp(abs_error, max=self.delta)\n",
    "        linear = abs_error - quadratic\n",
    "        loss = 0.5 * quadratic**2 + self.delta * linear\n",
    "        return loss.mean()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = HuberLoss(delta=5.0)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=INITIAL_LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=7, verbose=True, min_lr=1e-6\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Initial LR: {INITIAL_LR}\")\n",
    "print(f\"  Loss: Huber (delta=5.0)\")\n",
    "print(f\"  Optimizer: AdamW with weight decay\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  Early stopping patience: {PATIENCE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54371b0c",
   "metadata": {},
   "source": [
    "## 9. Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, features, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images, features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(targets.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    return total_loss / len(dataloader), mae, rmse, r2, predictions, actuals\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_mae': [], 'val_mae': [],\n",
    "    'train_rmse': [], 'val_rmse': [],\n",
    "    'train_r2': [], 'val_r2': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_mae = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ TRAINING STARTED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds = []\n",
    "    train_actuals = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for images, features, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.detach().cpu().numpy())\n",
    "        train_actuals.extend(targets.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_preds = np.array(train_preds)\n",
    "    train_actuals = np.array(train_actuals)\n",
    "    train_mae = mean_absolute_error(train_actuals, train_preds)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_actuals, train_preds))\n",
    "    train_r2 = r2_score(train_actuals, train_preds)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_mae, val_rmse, val_r2, val_preds, val_actuals = evaluate_model(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_mae)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss / len(train_loader))\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['train_rmse'].append(train_rmse)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    history['train_r2'].append(train_r2)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}:\")\n",
    "    print(f\"  Train - Loss: {train_loss/len(train_loader):.4f}, MAE: {train_mae:.3f}, RMSE: {train_rmse:.3f}, R¬≤: {train_r2:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, MAE: {val_mae:.3f}, RMSE: {val_rmse:.3f}, R¬≤: {val_r2:.4f}\")\n",
    "    print(f\"  LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Early stopping and best model saving\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ‚úÖ New best model! Val MAE: {val_mae:.3f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  ‚è≥ No improvement for {epochs_no_improve} epochs\")\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"\\n‚èπÔ∏è Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\n‚úÖ Training complete! Best Val MAE: {best_val_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782744e",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_title('Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE plot\n",
    "axes[0, 1].plot(history['train_mae'], label='Train MAE', linewidth=2)\n",
    "axes[0, 1].plot(history['val_mae'], label='Val MAE', linewidth=2)\n",
    "axes[0, 1].axhline(y=5, color='r', linestyle='--', label='Target: ¬±5 GSM', linewidth=2)\n",
    "axes[0, 1].set_title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('MAE (GSM)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE plot\n",
    "axes[1, 0].plot(history['train_rmse'], label='Train RMSE', linewidth=2)\n",
    "axes[1, 0].plot(history['val_rmse'], label='Val RMSE', linewidth=2)\n",
    "axes[1, 0].set_title('Root Mean Squared Error', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('RMSE (GSM)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# R¬≤ plot\n",
    "axes[1, 1].plot(history['train_r2'], label='Train R¬≤', linewidth=2)\n",
    "axes[1, 1].plot(history['val_r2'], label='Val R¬≤', linewidth=2)\n",
    "axes[1, 1].set_title('R¬≤ Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('R¬≤')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET_PATH}/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11213444",
   "metadata": {},
   "source": [
    "## 11. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58632d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_mae, test_rmse, test_r2, test_preds, test_actuals = evaluate_model(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä FINAL TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "print(f\"Test MAE:       {test_mae:.3f} GSM\")\n",
    "print(f\"Test RMSE:      {test_rmse:.3f} GSM\")\n",
    "print(f\"Test R¬≤:        {test_r2:.4f}\")\n",
    "print(f\"\\nüéØ Target: ¬±5 GSM prediction error\")\n",
    "print(f\"‚úÖ Achieved: ¬±{test_mae:.2f} GSM (MAE)\")\n",
    "\n",
    "if test_mae <= 5.0:\n",
    "    print(\"\\nüéâ SUCCESS! Model meets the ¬±5 GSM accuracy target!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Model is {test_mae - 5:.2f} GSM away from target\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Error distribution\n",
    "errors = test_preds - test_actuals\n",
    "within_5 = np.sum(np.abs(errors) <= 5) / len(errors) * 100\n",
    "within_10 = np.sum(np.abs(errors) <= 10) / len(errors) * 100\n",
    "\n",
    "print(f\"\\nüìà Error Analysis:\")\n",
    "print(f\"  Predictions within ¬±5 GSM:  {within_5:.1f}%\")\n",
    "print(f\"  Predictions within ¬±10 GSM: {within_10:.1f}%\")\n",
    "print(f\"  Max error: {np.abs(errors).max():.2f} GSM\")\n",
    "print(f\"  Min error: {np.abs(errors).min():.2f} GSM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a73ba8",
   "metadata": {},
   "source": [
    "## 12. Test Set Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed19a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Predicted vs Actual\n",
    "axes[0, 0].scatter(test_actuals, test_preds, alpha=0.6, s=80)\n",
    "axes[0, 0].plot([test_actuals.min(), test_actuals.max()], \n",
    "                [test_actuals.min(), test_actuals.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0, 0].fill_between([test_actuals.min(), test_actuals.max()],\n",
    "                        [test_actuals.min()-5, test_actuals.max()-5],\n",
    "                        [test_actuals.min()+5, test_actuals.max()+5],\n",
    "                        alpha=0.2, color='green', label='¬±5 GSM')\n",
    "axes[0, 0].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 0].set_title(f'Predicted vs Actual GSM\\n(R¬≤ = {test_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual plot\n",
    "residuals = test_preds - test_actuals\n",
    "axes[0, 1].scatter(test_actuals, residuals, alpha=0.6, s=80)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].axhline(y=5, color='g', linestyle=':', linewidth=2, alpha=0.5)\n",
    "axes[0, 1].axhline(y=-5, color='g', linestyle=':', linewidth=2, alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Residual (Predicted - Actual)', fontsize=12)\n",
    "axes[0, 1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error distribution\n",
    "axes[1, 0].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[1, 0].axvline(x=residuals.mean(), color='g', linestyle='-', linewidth=2, \n",
    "                   label=f'Mean: {residuals.mean():.2f}')\n",
    "axes[1, 0].set_xlabel('Prediction Error (GSM)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 0].set_title(f'Error Distribution\\n(MAE = {test_mae:.3f} GSM)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Absolute error vs actual GSM\n",
    "abs_errors = np.abs(residuals)\n",
    "axes[1, 1].scatter(test_actuals, abs_errors, alpha=0.6, s=80)\n",
    "axes[1, 1].axhline(y=5, color='r', linestyle='--', linewidth=2, label='¬±5 GSM Target')\n",
    "axes[1, 1].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Absolute Error (GSM)', fontsize=12)\n",
    "axes[1, 1].set_title('Absolute Error vs Actual GSM', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET_PATH}/test_prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Test visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6b3db",
   "metadata": {},
   "source": [
    "## 13. Save Model & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85292d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_save_path = f'{DATASET_PATH}/best_gsm_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'feature_cols': feature_cols,\n",
    "    'scaler': scaler,\n",
    "    'best_val_mae': best_val_mae,\n",
    "    'test_mae': test_mae,\n",
    "    'test_rmse': test_rmse,\n",
    "    'test_r2': test_r2,\n",
    "    'history': history\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save predictions\n",
    "results_df = df_test.copy()\n",
    "results_df['predicted_gsm'] = test_preds\n",
    "results_df['error'] = test_preds - test_actuals\n",
    "results_df['abs_error'] = np.abs(test_preds - test_actuals)\n",
    "results_df.to_csv(f'{DATASET_PATH}/test_predictions.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Predictions saved\")\n",
    "\n",
    "# Save metrics summary\n",
    "import json\n",
    "metrics_summary = {\n",
    "    'model': 'HybridGSMPredictor (EfficientNet-B3)',\n",
    "    'total_params': total_params,\n",
    "    'trainable_params': trainable_params,\n",
    "    'num_features': len(feature_cols),\n",
    "    'train_samples': len(df_train),\n",
    "    'val_samples': len(df_val),\n",
    "    'test_samples': len(df_test),\n",
    "    'best_val_mae': float(best_val_mae),\n",
    "    'test_mae': float(test_mae),\n",
    "    'test_rmse': float(test_rmse),\n",
    "    'test_r2': float(test_r2),\n",
    "    'predictions_within_5gsm': float(within_5),\n",
    "    'predictions_within_10gsm': float(within_10),\n",
    "    'target_achieved': test_mae <= 5.0\n",
    "}\n",
    "\n",
    "with open(f'{DATASET_PATH}/model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Metrics saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéä ALL RESULTS SAVED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a06719",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüß† Model Architecture:\")\n",
    "print(f\"  - Backbone: EfficientNet-B3 (ImageNet pretrained)\")\n",
    "print(f\"  - Input: 224x224 RGB images + {len(feature_cols)} fabric features\")\n",
    "print(f\"  - Total parameters: {total_params:,}\")\n",
    "print(f\"  - Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"  - Test MAE:  {test_mae:.3f} GSM\")\n",
    "print(f\"  - Test RMSE: {test_rmse:.3f} GSM\")\n",
    "print(f\"  - Test R¬≤:   {test_r2:.4f}\")\n",
    "print(f\"  - Within ¬±5 GSM:  {within_5:.1f}%\")\n",
    "print(f\"  - Within ¬±10 GSM: {within_10:.1f}%\")\n",
    "\n",
    "print(f\"\\nüìÅ Dataset:\")\n",
    "print(f\"  - Total samples: {len(df_train) + len(df_val) + len(df_test)}\")\n",
    "print(f\"  - Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")\n",
    "print(f\"  - No augmentation used\")\n",
    "\n",
    "if test_mae <= 5.0:\n",
    "    print(f\"\\nüéâ SUCCESS! Model achieves ¬±{test_mae:.2f} GSM accuracy\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Model is {test_mae - 5:.2f} GSM away from ¬±5 GSM target\")\n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    print(f\"  - Collect more training samples\")\n",
    "    print(f\"  - Try data augmentation\")\n",
    "    print(f\"  - Experiment with different architectures\")\n",
    "    print(f\"  - Fine-tune hyperparameters\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÅ TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
