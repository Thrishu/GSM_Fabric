{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Accurate GSM Prediction: CatBoost + Optuna\n",
                "\n",
                "## Objective\n",
                "Achieve a Mean Absolute Error (MAE) of **‚â§ 5 GSM** on fabric samples using 64 extracted computer vision features.\n",
                "\n",
                "## Dataset\n",
                "Using the augmented dataset (~1000 samples) containing engineered features:\n",
                "- `weft_count`, `warp_count` (Thread counting)\n",
                "- `weft_spacing_avg`, `warp_spacing_avg` (Density)\n",
                "- `yarn_avg_area`, `yarn_std_area` (Yarn properties)\n",
                "- `texture_energy`, `texture_entropy` (Surface texture)\n",
                "- Frequency domain features (FFT/Gabor filters)\n",
                "\n",
                "## Methodology\n",
                "1. **Load Data**: Use `dataset_train.csv`, `dataset_val.csv`, `dataset_test.csv` from the augmented features folder.\n",
                "2. **Preprocessing**: Robust scaling to handle outliers.\n",
                "3. **Model**: **CatBoost Regressor** (Gradient Boosting).\n",
                "4. **Optimization**: **Optuna** for Bayesian hyperparameter tuning to minimize MAE.\n",
                "5. **Evaluation**: \n",
                "    - 5-Fold Cross-Validation.\n",
                "    - Feature Importance Analysis (SHAP).\n",
                "    - Error Analysis (Predicted vs Actual).\n",
                "\n",
                "---\n",
                "\n",
                "### 1. Setup & Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install catboost optuna shap -q\n",
                "\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
                "from sklearn.preprocessing import RobustScaler\n",
                "from catboost import CatBoostRegressor, Pool\n",
                "import optuna\n",
                "import shap\n",
                "import warnings\n",
                "import json\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette(\"husl\")\n",
                "\n",
                "print(\"‚úÖ Libraries Installed & Imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Data Loading\n",
                "We load the augmented datasets which contain the 64 engineered features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive (for Colab)\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    IN_COLAB = True\n",
                "    BASE_PATH = '/content/drive/MyDrive/fabric_gsm_pipeline'\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "    BASE_PATH = 'data' # Change this to your local path if not in Colab\n",
                "    print(\"Running locally\")\n",
                "\n",
                "# Dataset paths\n",
                "DATASET_PATH = f\"{BASE_PATH}/augmented_features_dataset\"\n",
                "TRAIN_CSV = f\"{DATASET_PATH}/dataset_train.csv\"\n",
                "VAL_CSV = f\"{DATASET_PATH}/dataset_val.csv\"\n",
                "TEST_CSV = f\"{DATASET_PATH}/dataset_test.csv\"\n",
                "\n",
                "# Load Data\n",
                "df_train = pd.read_csv(TRAIN_CSV)\n",
                "df_val = pd.read_csv(VAL_CSV)\n",
                "df_test = pd.read_csv(TEST_CSV)\n",
                "\n",
                "# Combine Train and Val for Cross-Validation during tuning\n",
                "df_train_full = pd.concat([df_train, df_val], axis=0).reset_index(drop=True)\n",
                "\n",
                "print(f\"Train samples: {len(df_train)}\")\n",
                "print(f\"Val samples:   {len(df_val)}\")\n",
                "print(f\"Test samples:  {len(df_test)}\")\n",
                "print(f\"Total samples: {len(df_train_full) + len(df_test)}\")\n",
                "\n",
                "# Target Column\n",
                "TARGET = 'gsm'\n",
                "\n",
                "# Identify Features (exclude metadata)\n",
                "meta_cols = ['image_name', 'gsm', 'source', 'augmentation', 'original_image', 'split']\n",
                "features = [col for col in df_train.columns if col not in meta_cols]\n",
                "\n",
                "print(f\"\\nüî¨ Features used ({len(features)}): {features[:5]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Preprocessing\n",
                "- **RobustScaler**: Used to scale features. It is robust to outliers which might be present in CV-extracted features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize Scaler\n",
                "scaler = RobustScaler()\n",
                "\n",
                "# Fit on Full Train Set (Train + Val)\n",
                "X = df_train_full[features]\n",
                "y = df_train_full[TARGET]\n",
                "\n",
                "X_test = df_test[features]\n",
                "y_test = df_test[TARGET]\n",
                "\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Convert back to DataFrame for convenience with CatBoost (keeps column names)\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
                "X_test_scaled = pd.DataFrame(X_test_scaled, columns=features)\n",
                "\n",
                "print(\"‚úÖ Data Scaled using RobustScaler\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Hyperparameter Tuning using Optuna\n",
                "We use Optuna to find the best hyperparameters for CatBoost to minimize Mean Absolute Error (MAE)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def objective(trial):\n",
                "    params = {\n",
                "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
                "        'depth': trial.suggest_int('depth', 4, 10),\n",
                "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
                "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10, log=True),\n",
                "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n",
                "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
                "        'loss_function': 'MAE',  # Directly optimize visually interpretable metric\n",
                "        'verbose': False,\n",
                "        'random_seed': 42,\n",
                "        'task_type': 'CPU' # Or GPU if available\n",
                "    }\n",
                "\n",
                "    # 5-Fold Cross-Validation within Optuna\n",
                "    cv_data = Pool(data=X_scaled, label=y)\n",
                "    \n",
                "    from catboost import cv\n",
                "    \n",
                "    scores = cv(\n",
                "        pool=cv_data,\n",
                "        params=params,\n",
                "        fold_count=5,\n",
                "        seed=42,\n",
                "        shuffle=True,\n",
                "        stratified=False,\n",
                "        plot=False,\n",
                "        verbose=False\n",
                "    )\n",
                "    \n",
                "    # Minimize Best Validation MAE\n",
                "    return min(scores['test-MAE-mean'])\n",
                "\n",
                "print(\"‚è≥ Starting Optuna Optimization...\")\n",
                "study = optuna.create_study(direction='minimize')\n",
                "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
                "\n",
                "print(\"\\nüèÜ Best Params:\", study.best_params)\n",
                "print(\"üèÜ Best CV MAE:\", study.best_value)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Final Model Training\n",
                "Train variables on the full training set using the best parameters found."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "best_params = study.best_params\n",
                "best_params['loss_function'] = 'MAE'\n",
                "best_params['verbose'] = 100\n",
                "best_params['random_seed'] = 42\n",
                "\n",
                "# Final Training\n",
                "model = CatBoostRegressor(**best_params)\n",
                "model.fit(X_scaled, y, eval_set=(X_test_scaled, y_test), early_stopping_rounds=50, verbose=100)\n",
                "\n",
                "print(\"\\n‚úÖ Model Training Completed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Evaluation on Test Set\n",
                "Checking if we met the **MAE ‚â§ 5** criteria."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = model.predict(X_test_scaled)\n",
                "\n",
                "# Metrics\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print(\"=\"*40)\n",
                "print(\"üß™ FINAL TEST RESULTS\")\n",
                "print(\"=\"*40)\n",
                "print(f\"MAE:  {mae:.4f} GSM\")\n",
                "print(f\"RMSE: {rmse:.4f} GSM\")\n",
                "print(f\"R¬≤:   {r2:.4f}\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# Success Check\n",
                "if mae <= 5.0:\n",
                "    print(\"üéâ SUCCESS: MAE is within ¬±5 GSM target!\")\n",
                "else:\n",
                "    print(f\"‚ö†Ô∏è WARNING: MAE {mae:.2f} is above ¬±5 target.\")\n",
                "\n",
                "# Visualizing Predictions\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(y_test, y_pred, alpha=0.6, color='blue', edgecolor='k', label='Samples')\n",
                "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=3, label='Perfect Prediction')\n",
                "\n",
                "# Tolerance Band\n",
                "plt.fill_between([y.min(), y.max()], \n",
                "                 [y.min()-5, y.max()-5], \n",
                "                 [y.min()+5, y.max()+5], \n",
                "                 color='green', alpha=0.1, label='¬±5 GSM Tolerance')\n",
                "\n",
                "plt.xlabel('Actual GSM')\n",
                "plt.ylabel('Predicted GSM')\n",
                "plt.title(f'Actual vs Predicted GSM (Test Set)\\nMAE: {mae:.2f}')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. Feature Importance Analysis\n",
                "Understanding what drives the predictions (Physics check)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feature_importances = model.get_feature_importance()\n",
                "feature_names = X_scaled.columns\n",
                "\n",
                "# Create DataFrame\n",
                "fi_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
                "fi_df = fi_df.sort_values(by='importance', ascending=False).head(20)\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(12, 8))\n",
                "sns.barplot(x='importance', y='feature', data=fi_df, palette='viridis')\n",
                "plt.title('Top 20 Important Features for GSM Prediction')\n",
                "plt.xlabel('CatBoost Feature Importance')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8. Save Model\n",
                "Saving the trained model for future inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_save_path = \"catboost_gsm_model.cbm\"\n",
                "model.save_model(model_save_path)\n",
                "print(f\"‚úÖ Model saved to {model_save_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
