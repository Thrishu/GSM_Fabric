{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0db3ab1",
   "metadata": {},
   "source": [
    "# üßµ Research-Grade GSM Prediction from Fabric Microscopy Images\n",
    "\n",
    "## Hybrid Deep Learning Approach for Fabric Weight Estimation\n",
    "\n",
    "**Research Objective:** Develop a highly accurate GSM (Grams per Square Meter) prediction model combining:\n",
    "- Pre-trained CNN features (transfer learning from ImageNet)\n",
    "- Engineered fabric-specific features (thread count, texture, frequency domain)\n",
    "\n",
    "**Target Accuracy:** ¬±5 GSM prediction error\n",
    "\n",
    "**Dataset:** 1,062 augmented microscopy images with 64 extracted fabric features\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start (Google Colab)\n",
    "1. Upload `augmented_features_dataset` folder to Google Drive\n",
    "2. Mount Drive and set `DATASET_PATH` below\n",
    "3. Run all cells sequentially\n",
    "4. Model will be saved to Drive after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6aff2e",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & GPU Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e68f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"\\n‚úÖ Environment configured with seed:\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625af763",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d744fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "    BASE_PATH = '/content/drive/MyDrive/fabric_gsm_pipeline'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    BASE_PATH = 'data'\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_PATH = f\"{BASE_PATH}/augmented_features_dataset\"\n",
    "IMAGES_PATH = f\"{DATASET_PATH}/images\"\n",
    "TRAIN_CSV = f\"{DATASET_PATH}/dataset_train.csv\"\n",
    "VAL_CSV = f\"{DATASET_PATH}/dataset_val.csv\"\n",
    "TEST_CSV = f\"{DATASET_PATH}/dataset_test.csv\"\n",
    "\n",
    "print(f\"Dataset path: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7ac3c",
   "metadata": {},
   "source": [
    "## 3. Import Libraries & Visualization Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ed105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b6d92",
   "metadata": {},
   "source": [
    "## 4. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23793707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val = pd.read_csv(VAL_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train samples: {len(df_train)}\")\n",
    "print(f\"Val samples:   {len(df_val)}\")\n",
    "print(f\"Test samples:  {len(df_test)}\")\n",
    "print(f\"Total:         {len(df_train) + len(df_val) + len(df_test)}\")\n",
    "\n",
    "# Feature columns (exclude metadata)\n",
    "meta_cols = ['image_name', 'gsm', 'source', 'augmentation', 'original_image', 'split']\n",
    "feature_cols = [col for col in df_train.columns if col not in meta_cols]\n",
    "\n",
    "print(f\"\\nüî¨ Extracted features: {len(feature_cols)}\")\n",
    "print(f\"Feature names: {feature_cols[:5]}... (showing first 5)\")\n",
    "\n",
    "# GSM distribution\n",
    "print(\"\\nüìä GSM Distribution:\")\n",
    "print(f\"Train - Mean: {df_train['gsm'].mean():.2f}, Std: {df_train['gsm'].std():.2f}, Range: [{df_train['gsm'].min():.0f}, {df_train['gsm'].max():.0f}]\")\n",
    "print(f\"Val   - Mean: {df_val['gsm'].mean():.2f}, Std: {df_val['gsm'].std():.2f}, Range: [{df_val['gsm'].min():.0f}, {df_val['gsm'].max():.0f}]\")\n",
    "print(f\"Test  - Mean: {df_test['gsm'].mean():.2f}, Std: {df_test['gsm'].std():.2f}, Range: [{df_test['gsm'].min():.0f}, {df_test['gsm'].max():.0f}]\")\n",
    "\n",
    "# Visualize GSM distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, (df, name) in enumerate([(df_train, 'Train'), (df_val, 'Val'), (df_test, 'Test')]):\n",
    "    axes[i].hist(df['gsm'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'{name} GSM Distribution')\n",
    "    axes[i].set_xlabel('GSM (g/m¬≤)')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].axvline(df['gsm'].mean(), color='red', linestyle='--', label=f\"Mean: {df['gsm'].mean():.1f}\")\n",
    "    axes[i].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dataset loaded and explored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381480c",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"üîß Preprocessing extracted features...\")\n",
    "\n",
    "# Fill NaN with median for each feature\n",
    "for col in feature_cols:\n",
    "    if df_train[col].isna().any():\n",
    "        median_val = df_train[col].median()\n",
    "        df_train[col].fillna(median_val, inplace=True)\n",
    "        df_val[col].fillna(median_val, inplace=True)\n",
    "        df_test[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Remove features with zero variance\n",
    "zero_var_cols = []\n",
    "for col in feature_cols:\n",
    "    if df_train[col].std() == 0:\n",
    "        zero_var_cols.append(col)\n",
    "\n",
    "if zero_var_cols:\n",
    "    print(f\"Removing {len(zero_var_cols)} zero-variance features: {zero_var_cols}\")\n",
    "    feature_cols = [col for col in feature_cols if col not in zero_var_cols]\n",
    "\n",
    "# Standardize features using RobustScaler (handles outliers better)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(df_train[feature_cols])\n",
    "X_val_scaled = scaler.transform(df_val[feature_cols])\n",
    "X_test_scaled = scaler.transform(df_test[feature_cols])\n",
    "\n",
    "print(f\"\\n‚úÖ Features preprocessed: {len(feature_cols)} features\")\n",
    "print(f\"Scaled shapes - Train: {X_train_scaled.shape}, Val: {X_val_scaled.shape}, Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00626100",
   "metadata": {},
   "source": [
    "## 6. Custom Dataset Class (Hybrid: Images + Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c405ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FabricGSMDataset(Dataset):\n",
    "    \"\"\"Dataset combining images and engineered features for GSM prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, features_array, images_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.features = features_array\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.df.iloc[idx]['image_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get engineered features\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        \n",
    "        # Get target GSM\n",
    "        gsm = torch.tensor(self.df.iloc[idx]['gsm'], dtype=torch.float32)\n",
    "        \n",
    "        return image, features, gsm\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FabricGSMDataset(df_train, X_train_scaled, IMAGES_PATH, transform=train_transform)\n",
    "val_dataset = FabricGSMDataset(df_val, X_val_scaled, IMAGES_PATH, transform=val_test_transform)\n",
    "test_dataset = FabricGSMDataset(df_test, X_test_scaled, IMAGES_PATH, transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"‚úÖ Datasets created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fc893",
   "metadata": {},
   "source": [
    "## 7. Hybrid Deep Learning Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a43415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridGSMPredictor(nn.Module):\n",
    "    \"\"\"Hybrid model combining EfficientNet-B3 CNN with engineered fabric features.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, dropout=0.5):\n",
    "        super(HybridGSMPredictor, self).__init__()\n",
    "        \n",
    "        # Pre-trained EfficientNet-B3 backbone\n",
    "        efficientnet = models.efficientnet_b3(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Freeze early layers (feature extraction)\n",
    "        for param in list(efficientnet.parameters())[:-30]:\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Remove classifier head\n",
    "        self.cnn_features = nn.Sequential(*list(efficientnet.children())[:-1])\n",
    "        cnn_feature_size = 1536  # EfficientNet-B3 output\n",
    "        \n",
    "        # Feature processing branch\n",
    "        self.feature_branch = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout/2)\n",
    "        )\n",
    "        \n",
    "        # Fusion and prediction head\n",
    "        combined_size = cnn_feature_size + 128\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(combined_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout/2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, features):\n",
    "        # Extract CNN features\n",
    "        cnn_out = self.cnn_features(images)\n",
    "        cnn_out = torch.flatten(cnn_out, 1)\n",
    "        \n",
    "        # Process engineered features\n",
    "        feat_out = self.feature_branch(features)\n",
    "        \n",
    "        # Concatenate and predict\n",
    "        combined = torch.cat([cnn_out, feat_out], dim=1)\n",
    "        output = self.fusion(combined)\n",
    "        \n",
    "        return output.squeeze()\n",
    "\n",
    "# Initialize model\n",
    "model = HybridGSMPredictor(num_features=len(feature_cols), dropout=0.5)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üß† MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Backbone: EfficientNet-B3 (ImageNet pretrained)\")\n",
    "print(f\"Input features: {len(feature_cols)} fabric-specific features\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6225d88",
   "metadata": {},
   "source": [
    "## 8. Training Configuration & Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# =========================\n",
    "# Hyperparameters\n",
    "# =========================\n",
    "EPOCHS = 100\n",
    "INITIAL_LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PATIENCE = 15   # Early stopping patience\n",
    "\n",
    "# =========================\n",
    "# Custom Huber Loss\n",
    "# =========================\n",
    "class HuberLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Huber loss - robust to outliers.\n",
    "    Suitable for GSM regression with tolerance.\n",
    "    \"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        error = pred - target\n",
    "        abs_error = torch.abs(error)\n",
    "        quadratic = torch.clamp(abs_error, max=self.delta)\n",
    "        linear = abs_error - quadratic\n",
    "        loss = 0.5 * quadratic ** 2 + self.delta * linear\n",
    "        return loss.mean()\n",
    "\n",
    "# =========================\n",
    "# Loss, Optimizer\n",
    "# =========================\n",
    "criterion = HuberLoss(delta=5.0)   # ¬±5 GSM tolerance\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=INITIAL_LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# LR Scheduler (Colab-safe)\n",
    "# =========================\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Utility: Get Current LR\n",
    "# =========================\n",
    "def get_current_lr(optimizer):\n",
    "    return optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "# =========================\n",
    "# Config Summary\n",
    "# =========================\n",
    "print(\"‚úÖ Training configuration loaded\")\n",
    "print(f\"‚Ä¢ Epochs: {EPOCHS}\")\n",
    "print(f\"‚Ä¢ Initial LR: {INITIAL_LR}\")\n",
    "print(\"‚Ä¢ Loss: Huber Loss (delta=5.0)\")\n",
    "print(\"‚Ä¢ Optimizer: AdamW\")\n",
    "print(\"‚Ä¢ Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"‚Ä¢ Early Stopping Patience: {PATIENCE}\")\n",
    "print(f\"‚Ä¢ PyTorch Version: {torch.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817f3b8",
   "metadata": {},
   "source": [
    "## 9. Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc873fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, features, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images, features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(targets.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    \n",
    "    return total_loss / len(dataloader), mae, rmse, r2, predictions, actuals\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_mae': [], 'val_mae': [],\n",
    "    'train_rmse': [], 'val_rmse': [],\n",
    "    'train_r2': [], 'val_r2': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_mae = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ TRAINING STARTED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds = []\n",
    "    train_actuals = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "    for images, features, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.detach().cpu().numpy())\n",
    "        train_actuals.extend(targets.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_preds = np.array(train_preds)\n",
    "    train_actuals = np.array(train_actuals)\n",
    "    train_mae = mean_absolute_error(train_actuals, train_preds)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_actuals, train_preds))\n",
    "    train_r2 = r2_score(train_actuals, train_preds)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_mae, val_rmse, val_r2, val_preds, val_actuals = evaluate_model(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_mae)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss / len(train_loader))\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_mae'].append(train_mae)\n",
    "    history['val_mae'].append(val_mae)\n",
    "    history['train_rmse'].append(train_rmse)\n",
    "    history['val_rmse'].append(val_rmse)\n",
    "    history['train_r2'].append(train_r2)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}:\")\n",
    "    print(f\"  Train - Loss: {train_loss/len(train_loader):.4f}, MAE: {train_mae:.3f}, RMSE: {train_rmse:.3f}, R¬≤: {train_r2:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, MAE: {val_mae:.3f}, RMSE: {val_rmse:.3f}, R¬≤: {val_r2:.4f}\")\n",
    "    print(f\"  LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Early stopping and best model saving\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"  ‚úÖ New best model! Val MAE: {val_mae:.3f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  ‚è≥ No improvement for {epochs_no_improve} epochs\")\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"\\n‚èπÔ∏è Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\n‚úÖ Training complete! Best Val MAE: {best_val_mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8407c2",
   "metadata": {},
   "source": [
    "## 10. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0, 0].set_title('Loss over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE plot\n",
    "axes[0, 1].plot(history['train_mae'], label='Train MAE', linewidth=2)\n",
    "axes[0, 1].plot(history['val_mae'], label='Val MAE', linewidth=2)\n",
    "axes[0, 1].axhline(y=5, color='r', linestyle='--', label='Target: ¬±5 GSM', linewidth=2)\n",
    "axes[0, 1].set_title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('MAE (GSM)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE plot\n",
    "axes[1, 0].plot(history['train_rmse'], label='Train RMSE', linewidth=2)\n",
    "axes[1, 0].plot(history['val_rmse'], label='Val RMSE', linewidth=2)\n",
    "axes[1, 0].set_title('Root Mean Squared Error', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('RMSE (GSM)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# R¬≤ plot\n",
    "axes[1, 1].plot(history['train_r2'], label='Train R¬≤', linewidth=2)\n",
    "axes[1, 1].plot(history['val_r2'], label='Val R¬≤', linewidth=2)\n",
    "axes[1, 1].set_title('R¬≤ Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('R¬≤')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET_PATH}/training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Training history saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7381e1",
   "metadata": {},
   "source": [
    "## 10.1. Detailed Validation Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final validation predictions\n",
    "val_loss_final, val_mae_final, val_rmse_final, val_r2_final, val_preds_final, val_actuals_final = evaluate_model(\n",
    "    model, val_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä VALIDATION SET DETAILED METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Samples: {len(val_actuals_final)}\")\n",
    "print(f\"MAE:     {val_mae_final:.4f} GSM\")\n",
    "print(f\"RMSE:    {val_rmse_final:.4f} GSM\")\n",
    "print(f\"R¬≤:      {val_r2_final:.4f}\")\n",
    "print(f\"MSE:     {mean_squared_error(val_actuals_final, val_preds_final):.4f}\")\n",
    "\n",
    "# Percentile errors\n",
    "val_errors = val_preds_final - val_actuals_final\n",
    "val_abs_errors = np.abs(val_errors)\n",
    "\n",
    "print(f\"\\nüìà Error Percentiles:\")\n",
    "print(f\"  10th percentile: {np.percentile(val_abs_errors, 10):.2f} GSM\")\n",
    "print(f\"  25th percentile: {np.percentile(val_abs_errors, 25):.2f} GSM\")\n",
    "print(f\"  50th percentile (Median): {np.percentile(val_abs_errors, 50):.2f} GSM\")\n",
    "print(f\"  75th percentile: {np.percentile(val_abs_errors, 75):.2f} GSM\")\n",
    "print(f\"  90th percentile: {np.percentile(val_abs_errors, 90):.2f} GSM\")\n",
    "print(f\"  95th percentile: {np.percentile(val_abs_errors, 95):.2f} GSM\")\n",
    "print(f\"  99th percentile: {np.percentile(val_abs_errors, 99):.2f} GSM\")\n",
    "\n",
    "val_within_5 = np.sum(val_abs_errors <= 5) / len(val_abs_errors) * 100\n",
    "val_within_10 = np.sum(val_abs_errors <= 10) / len(val_abs_errors) * 100\n",
    "val_within_15 = np.sum(val_abs_errors <= 15) / len(val_abs_errors) * 100\n",
    "\n",
    "print(f\"\\n‚úÖ Accuracy Thresholds:\")\n",
    "print(f\"  Within ¬±5 GSM:  {val_within_5:.2f}% ({int(val_within_5 * len(val_actuals_final) / 100)}/{len(val_actuals_final)} samples)\")\n",
    "print(f\"  Within ¬±10 GSM: {val_within_10:.2f}% ({int(val_within_10 * len(val_actuals_final) / 100)}/{len(val_actuals_final)} samples)\")\n",
    "print(f\"  Within ¬±15 GSM: {val_within_15:.2f}% ({int(val_within_15 * len(val_actuals_final) / 100)}/{len(val_actuals_final)} samples)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Validation visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Validation Set Performance Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# 1. Predicted vs Actual\n",
    "axes[0, 0].scatter(val_actuals_final, val_preds_final, alpha=0.6, s=60, edgecolors='black', linewidth=0.5)\n",
    "axes[0, 0].plot([val_actuals_final.min(), val_actuals_final.max()], \n",
    "                [val_actuals_final.min(), val_actuals_final.max()], \n",
    "                'r--', linewidth=2.5, label='Perfect Prediction')\n",
    "axes[0, 0].fill_between([val_actuals_final.min(), val_actuals_final.max()],\n",
    "                        [val_actuals_final.min()-5, val_actuals_final.max()-5],\n",
    "                        [val_actuals_final.min()+5, val_actuals_final.max()+5],\n",
    "                        alpha=0.2, color='green', label='¬±5 GSM')\n",
    "axes[0, 0].set_xlabel('Actual GSM (g/m¬≤)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Predicted GSM (g/m¬≤)', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title(f'Predicted vs Actual\\nR¬≤ = {val_r2_final:.4f}', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=9)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual plot\n",
    "axes[0, 1].scatter(val_actuals_final, val_errors, alpha=0.6, s=60, edgecolors='black', linewidth=0.5)\n",
    "axes[0, 1].axhline(y=0, color='red', linestyle='--', linewidth=2.5, label='Zero Error')\n",
    "axes[0, 1].axhline(y=5, color='green', linestyle=':', linewidth=2, alpha=0.7, label='¬±5 GSM')\n",
    "axes[0, 1].axhline(y=-5, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Actual GSM (g/m¬≤)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Residual (Predicted - Actual)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title(f'Residual Plot\\nMean Error: {val_errors.mean():.3f} GSM', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=9)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error distribution\n",
    "axes[0, 2].hist(val_errors, bins=25, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 2].axvline(x=0, color='red', linestyle='--', linewidth=2.5, label='Zero Error')\n",
    "axes[0, 2].axvline(x=val_errors.mean(), color='orange', linestyle='-', linewidth=2.5, \n",
    "                   label=f'Mean: {val_errors.mean():.2f}')\n",
    "axes[0, 2].axvline(x=np.median(val_errors), color='purple', linestyle='-', linewidth=2.5,\n",
    "                   label=f'Median: {np.median(val_errors):.2f}')\n",
    "axes[0, 2].set_xlabel('Prediction Error (GSM)', fontsize=11, fontweight='bold')\n",
    "axes[0, 2].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "axes[0, 2].set_title(f'Error Distribution\\nStd: {val_errors.std():.3f} GSM', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].legend(fontsize=9)\n",
    "axes[0, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Absolute error vs actual\n",
    "axes[1, 0].scatter(val_actuals_final, val_abs_errors, alpha=0.6, s=60, c=val_abs_errors, \n",
    "                   cmap='RdYlGn_r', edgecolors='black', linewidth=0.5, vmin=0, vmax=15)\n",
    "axes[1, 0].axhline(y=5, color='red', linestyle='--', linewidth=2.5, label='¬±5 GSM Target')\n",
    "axes[1, 0].axhline(y=10, color='orange', linestyle=':', linewidth=2, label='¬±10 GSM')\n",
    "axes[1, 0].set_xlabel('Actual GSM (g/m¬≤)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Absolute Error (GSM)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title(f'Absolute Error vs Actual\\nMAE: {val_mae_final:.3f} GSM', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=9)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(axes[1, 0].collections[0], ax=axes[1, 0])\n",
    "cbar.set_label('Absolute Error (GSM)', fontsize=9)\n",
    "\n",
    "# 5. Cumulative error distribution\n",
    "sorted_abs_errors = np.sort(val_abs_errors)\n",
    "cumulative = np.arange(1, len(sorted_abs_errors) + 1) / len(sorted_abs_errors) * 100\n",
    "axes[1, 1].plot(sorted_abs_errors, cumulative, linewidth=2.5, color='darkblue')\n",
    "axes[1, 1].axvline(x=5, color='red', linestyle='--', linewidth=2, label=f'5 GSM ({val_within_5:.1f}%)')\n",
    "axes[1, 1].axvline(x=10, color='orange', linestyle='--', linewidth=2, label=f'10 GSM ({val_within_10:.1f}%)')\n",
    "axes[1, 1].axhline(y=50, color='gray', linestyle=':', linewidth=1.5, alpha=0.5)\n",
    "axes[1, 1].set_xlabel('Absolute Error (GSM)', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Cumulative Percentage (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Cumulative Error Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(fontsize=9)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xlim([0, max(20, sorted_abs_errors.max())])\n",
    "\n",
    "# 6. Box plot by GSM ranges\n",
    "gsm_ranges = pd.cut(val_actuals_final, bins=[0, 100, 150, 200, 250, 300], \n",
    "                    labels=['<100', '100-150', '150-200', '200-250', '>250'])\n",
    "error_by_range = [val_abs_errors[gsm_ranges == label] for label in gsm_ranges.categories]\n",
    "bp = axes[1, 2].boxplot(error_by_range, labels=gsm_ranges.categories, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1, 2].axhline(y=5, color='red', linestyle='--', linewidth=2, label='Target: ¬±5 GSM')\n",
    "axes[1, 2].set_xlabel('GSM Range (g/m¬≤)', fontsize=11, fontweight='bold')\n",
    "axes[1, 2].set_ylabel('Absolute Error (GSM)', fontsize=11, fontweight='bold')\n",
    "axes[1, 2].set_title('Error Distribution by GSM Range', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].legend(fontsize=9)\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET_PATH}/validation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Validation analysis complete and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f45336",
   "metadata": {},
   "source": [
    "## 11. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_mae, test_rmse, test_r2, test_preds, test_actuals = evaluate_model(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä FINAL TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "print(f\"Test MAE:       {test_mae:.3f} GSM\")\n",
    "print(f\"Test RMSE:      {test_rmse:.3f} GSM\")\n",
    "print(f\"Test R¬≤:        {test_r2:.4f}\")\n",
    "print(f\"\\nüéØ Target: ¬±5 GSM prediction error\")\n",
    "print(f\"‚úÖ Achieved: ¬±{test_mae:.2f} GSM (MAE)\")\n",
    "\n",
    "if test_mae <= 5.0:\n",
    "    print(\"\\nüéâ SUCCESS! Model meets the ¬±5 GSM accuracy target!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Model is {test_mae - 5:.2f} GSM away from target\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Error distribution\n",
    "errors = test_preds - test_actuals\n",
    "within_5 = np.sum(np.abs(errors) <= 5) / len(errors) * 100\n",
    "within_10 = np.sum(np.abs(errors) <= 10) / len(errors) * 100\n",
    "\n",
    "print(f\"\\nüìà Error Analysis:\")\n",
    "print(f\"  Predictions within ¬±5 GSM:  {within_5:.1f}%\")\n",
    "print(f\"  Predictions within ¬±10 GSM: {within_10:.1f}%\")\n",
    "print(f\"  Max error: {np.abs(errors).max():.2f} GSM\")\n",
    "print(f\"  Min error: {np.abs(errors).min():.2f} GSM\")\n",
    "\n",
    "# Detailed percentile analysis\n",
    "print(f\"\\nüìä Error Percentiles (Test Set):\")\n",
    "print(f\"  10th: {np.percentile(np.abs(errors), 10):.2f} GSM\")\n",
    "print(f\"  25th: {np.percentile(np.abs(errors), 25):.2f} GSM\")\n",
    "print(f\"  50th (Median): {np.percentile(np.abs(errors), 50):.2f} GSM\")\n",
    "print(f\"  75th: {np.percentile(np.abs(errors), 75):.2f} GSM\")\n",
    "print(f\"  90th: {np.percentile(np.abs(errors), 90):.2f} GSM\")\n",
    "print(f\"  95th: {np.percentile(np.abs(errors), 95):.2f} GSM\")\n",
    "print(f\"  99th: {np.percentile(np.abs(errors), 99):.2f} GSM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb6642",
   "metadata": {},
   "source": [
    "## 12. Comprehensive Test Set Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dffe89",
   "metadata": {},
   "source": [
    "## 12.1. Detailed Metrics Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive metrics comparison table\n",
    "# Get final validation metrics\n",
    "val_loss_final, val_mae_final, val_rmse_final, val_r2_final, val_preds_final, val_actuals_final = evaluate_model(\n",
    "    model, val_loader, criterion, device\n",
    ")\n",
    "val_errors_final = val_preds_final - val_actuals_final\n",
    "val_within_5 = np.sum(np.abs(val_errors_final) <= 5) / len(val_errors_final) * 100\n",
    "val_within_10 = np.sum(np.abs(val_errors_final) <= 10) / len(val_errors_final) * 100\n",
    "\n",
    "metrics_data = {\n",
    "    'Dataset': ['Training', 'Validation', 'Test'],\n",
    "    'Samples': [len(df_train), len(df_val), len(df_test)],\n",
    "    'MAE (GSM)': [\n",
    "        history['train_mae'][-1] if history['train_mae'] else 0,\n",
    "        val_mae_final,\n",
    "        test_mae\n",
    "    ],\n",
    "    'RMSE (GSM)': [\n",
    "        history['train_rmse'][-1] if history['train_rmse'] else 0,\n",
    "        val_rmse_final,\n",
    "        test_rmse\n",
    "    ],\n",
    "    'R¬≤ Score': [\n",
    "        history['train_r2'][-1] if history['train_r2'] else 0,\n",
    "        val_r2_final,\n",
    "        test_r2\n",
    "    ],\n",
    "    'Within ¬±5 GSM (%)': [\n",
    "        '-',  # Not calculated for train\n",
    "        f'{val_within_5:.2f}',\n",
    "        f'{within_5:.2f}'\n",
    "    ],\n",
    "    'Within ¬±10 GSM (%)': [\n",
    "        '-',\n",
    "        f'{val_within_10:.2f}',\n",
    "        f'{within_10:.2f}'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä COMPREHENSIVE METRICS COMPARISON TABLE\")\n",
    "print(\"=\"*100)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Styled table visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table_data = []\n",
    "for idx, row in metrics_df.iterrows():\n",
    "    table_data.append(list(row))\n",
    "\n",
    "table = ax.table(cellText=table_data, colLabels=metrics_df.columns,\n",
    "                cellLoc='center', loc='center',\n",
    "                colWidths=[0.12, 0.10, 0.12, 0.13, 0.11, 0.17, 0.19])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(metrics_df.columns)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Style rows\n",
    "colors = ['#E8F5E9', '#F1F8E9', '#FFF9C4']\n",
    "for i in range(len(metrics_df)):\n",
    "    for j in range(len(metrics_df.columns)):\n",
    "        table[(i+1, j)].set_facecolor(colors[i])\n",
    "        if j >= 2:  # Numeric columns\n",
    "            table[(i+1, j)].set_text_props(weight='bold')\n",
    "\n",
    "plt.title('Model Performance Metrics Comparison', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.savefig(f'{DATASET_PATH}/metrics_comparison_table.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Export metrics table\n",
    "metrics_df.to_csv(f'{DATASET_PATH}/metrics_comparison.csv', index=False)\n",
    "print(f\"\\n‚úÖ Metrics comparison table saved\")\n",
    "\n",
    "# Detailed test statistics\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìà DETAILED TEST SET STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n1Ô∏è‚É£ Central Tendency:\")\n",
    "print(f\"   Mean Error:             {errors.mean():+.4f} GSM\")\n",
    "print(f\"   Median Error:           {np.median(errors):+.4f} GSM\")\n",
    "print(f\"   Mean Absolute Error:    {test_mae:.4f} GSM\")\n",
    "print(f\"   Median Absolute Error:  {np.median(np.abs(errors)):.4f} GSM\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ Spread:\")\n",
    "print(f\"   Standard Deviation:     {errors.std():.4f} GSM\")\n",
    "print(f\"   Variance:               {errors.var():.4f}\")\n",
    "print(f\"   IQR (25th-75th):        {np.percentile(np.abs(errors), 75) - np.percentile(np.abs(errors), 25):.4f} GSM\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ Extreme Values:\")\n",
    "print(f\"   Maximum Error:          {errors.max():+.4f} GSM\")\n",
    "print(f\"   Minimum Error:          {errors.min():+.4f} GSM\")\n",
    "print(f\"   Max Absolute Error:     {np.abs(errors).max():.4f} GSM\")\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£ Accuracy Buckets:\")\n",
    "within_thresholds = [2.5, 5.0, 7.5, 10.0, 15.0, 20.0]\n",
    "for threshold in within_thresholds:\n",
    "    pct = np.sum(np.abs(errors) <= threshold) / len(errors) * 100\n",
    "    count = int(pct * len(errors) / 100)\n",
    "    status = \"‚úÖ\" if threshold <= 5 and pct >= 70 else \"üìä\"\n",
    "    print(f\"   {status} Within ¬±{threshold:4.1f} GSM: {pct:5.2f}% ({count:3d}/{len(errors)} samples)\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b1779",
   "metadata": {},
   "source": [
    "## 12.2. Comprehensive Performance Visualizations (9-Panel Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5744e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive 9-panel visualization\n",
    "fig = plt.figure(figsize=(22, 14))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "fig.suptitle('Comprehensive Test Set Performance Analysis', fontsize=20, fontweight='bold', y=0.995)\n",
    "\n",
    "# 1. Predicted vs Actual with density coloring\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "from scipy.stats import gaussian_kde\n",
    "xy = np.vstack([test_actuals, test_preds])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "scatter = ax1.scatter(test_actuals, test_preds, c=z, s=90, alpha=0.7, cmap='viridis', \n",
    "                     edgecolors='black', linewidth=0.6)\n",
    "ax1.plot([test_actuals.min(), test_actuals.max()], \n",
    "         [test_actuals.min(), test_actuals.max()], \n",
    "         'r--', linewidth=3, label='Perfect Prediction', zorder=5)\n",
    "ax1.fill_between([test_actuals.min(), test_actuals.max()],\n",
    "                 [test_actuals.min()-5, test_actuals.max()-5],\n",
    "                 [test_actuals.min()+5, test_actuals.max()+5],\n",
    "                 alpha=0.15, color='green', label='¬±5 GSM Zone', zorder=1)\n",
    "ax1.set_xlabel('Actual GSM (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Predicted GSM (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax1.set_title(f'Predicted vs Actual (Density)\\nR¬≤={test_r2:.4f}, MAE={test_mae:.2f}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11, loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter, ax=ax1)\n",
    "cbar1.set_label('Point Density', fontsize=11)\n",
    "\n",
    "# 2. Residual plot with polynomial trend\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sc2 = ax2.scatter(test_actuals, errors, alpha=0.7, s=90, c=np.abs(errors), cmap='RdYlGn_r', \n",
    "                  edgecolors='black', linewidth=0.6, vmin=0, vmax=15)\n",
    "# Add trend line\n",
    "z = np.polyfit(test_actuals, errors, 2)\n",
    "p = np.poly1d(z)\n",
    "x_trend = np.linspace(test_actuals.min(), test_actuals.max(), 100)\n",
    "ax2.plot(x_trend, p(x_trend), \"b-\", linewidth=3, alpha=0.8, label='Polynomial Trend')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=3, label='Zero Error', zorder=5)\n",
    "ax2.axhline(y=5, color='green', linestyle=':', linewidth=2.5, alpha=0.7)\n",
    "ax2.axhline(y=-5, color='green', linestyle=':', linewidth=2.5, alpha=0.7)\n",
    "ax2.set_xlabel('Actual GSM (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Residual Error (GSM)', fontsize=13, fontweight='bold')\n",
    "ax2.set_title(f'Residual Analysis\\nMean={errors.mean():+.3f}, Std={errors.std():.3f}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "cbar2 = plt.colorbar(sc2, ax=ax2)\n",
    "cbar2.set_label('|Error| (GSM)', fontsize=11)\n",
    "\n",
    "# 3. Error distribution with statistical fit\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "n, bins, patches = ax3.hist(errors, bins=30, edgecolor='black', alpha=0.75, color='skyblue', density=True)\n",
    "# Overlay normal distribution\n",
    "mu, sigma = errors.mean(), errors.std()\n",
    "x = np.linspace(errors.min(), errors.max(), 100)\n",
    "ax3.plot(x, (1/(sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma)**2), \n",
    "         'r-', linewidth=3, label=f'Normal(Œº={mu:.2f}, œÉ={sigma:.2f})')\n",
    "ax3.axvline(x=0, color='darkred', linestyle='--', linewidth=3, label='Zero', zorder=5)\n",
    "ax3.axvline(x=mu, color='orange', linestyle='-', linewidth=3, label=f'Mean', zorder=5)\n",
    "ax3.axvline(x=np.median(errors), color='purple', linestyle='-', linewidth=3, \n",
    "            label=f'Median', zorder=5)\n",
    "ax3.set_xlabel('Prediction Error (GSM)', fontsize=13, fontweight='bold')\n",
    "ax3.set_ylabel('Probability Density', fontsize=13, fontweight='bold')\n",
    "ax3.set_title('Error Distribution with Normal Fit', fontsize=14, fontweight='bold')\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Heatmap: Error distribution by GSM ranges\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "gsm_bins = pd.cut(test_actuals, bins=8)\n",
    "error_bins = pd.cut(np.abs(errors), bins=[0, 2.5, 5, 7.5, 10, 15, 100])\n",
    "heatmap_data = pd.crosstab(gsm_bins, error_bins)\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='d', cmap='RdYlGn_r', ax=ax4, \n",
    "            cbar_kws={'label': 'Sample Count'}, linewidths=0.5, linecolor='gray')\n",
    "ax4.set_xlabel('Absolute Error Range (GSM)', fontsize=13, fontweight='bold')\n",
    "ax4.set_ylabel('Actual GSM Range (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax4.set_title('Error Distribution Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.setp(ax4.get_xticklabels(), rotation=45, ha='right', fontsize=10)\n",
    "plt.setp(ax4.get_yticklabels(), rotation=0, fontsize=10)\n",
    "\n",
    "# 5. Cumulative error distribution (CDF)\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "sorted_abs_errors = np.sort(np.abs(errors))\n",
    "cumulative = np.arange(1, len(sorted_abs_errors) + 1) / len(sorted_abs_errors) * 100\n",
    "ax5.plot(sorted_abs_errors, cumulative, linewidth=3.5, color='darkblue', label='Cumulative %')\n",
    "ax5.axvline(x=5, color='red', linestyle='--', linewidth=3, label=f'5 GSM ({within_5:.1f}%)')\n",
    "ax5.axvline(x=10, color='orange', linestyle='--', linewidth=3, label=f'10 GSM ({within_10:.1f}%)')\n",
    "ax5.axhline(y=50, color='gray', linestyle=':', linewidth=2, alpha=0.6, label='Median')\n",
    "ax5.axhline(y=90, color='gray', linestyle=':', linewidth=2, alpha=0.6, label='90th %ile')\n",
    "ax5.fill_between(sorted_abs_errors, 0, cumulative, alpha=0.3, color='blue')\n",
    "ax5.set_xlabel('Absolute Error (GSM)', fontsize=13, fontweight='bold')\n",
    "ax5.set_ylabel('Cumulative Percentage (%)', fontsize=13, fontweight='bold')\n",
    "ax5.set_title('Cumulative Distribution Function', fontsize=14, fontweight='bold')\n",
    "ax5.legend(fontsize=11)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "ax5.set_xlim([0, min(25, sorted_abs_errors.max())])\n",
    "\n",
    "# 6. Violin + Box plot by GSM ranges\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "gsm_ranges = pd.cut(test_actuals, bins=[0, 100, 150, 200, 250, 300], \n",
    "                    labels=['<100', '100-150', '150-200', '200-250', '>250'])\n",
    "error_by_range = [np.abs(errors)[gsm_ranges == label] for label in gsm_ranges.categories \n",
    "                  if np.sum(gsm_ranges == label) > 0]\n",
    "positions = range(1, len(error_by_range) + 1)\n",
    "vp = ax6.violinplot(error_by_range, positions=positions, showmeans=True, showmedians=True, \n",
    "                    widths=0.7)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_facecolor('lightcoral')\n",
    "    pc.set_alpha(0.6)\n",
    "bp = ax6.boxplot(error_by_range, positions=positions, widths=0.35, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.8),\n",
    "                medianprops=dict(color='red', linewidth=2.5))\n",
    "ax6.axhline(y=5, color='red', linestyle='--', linewidth=3, label='Target: ¬±5 GSM', zorder=5)\n",
    "ax6.set_xticks(positions)\n",
    "ax6.set_xticklabels([label for label in gsm_ranges.categories if np.sum(gsm_ranges == label) > 0], \n",
    "                     fontsize=11)\n",
    "ax6.set_xlabel('GSM Range (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax6.set_ylabel('Absolute Error (GSM)', fontsize=13, fontweight='bold')\n",
    "ax6.set_title('Error by GSM Range (Violin + Box)', fontsize=14, fontweight='bold')\n",
    "ax6.legend(fontsize=11)\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 7. Sequential error analysis\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "indices = np.arange(len(errors))\n",
    "sc7 = ax7.scatter(indices, errors, alpha=0.6, s=70, c=np.abs(errors), cmap='RdYlGn_r',\n",
    "                 edgecolors='black', linewidth=0.4, vmin=0, vmax=15)\n",
    "ax7.axhline(y=0, color='red', linestyle='--', linewidth=2.5, zorder=5)\n",
    "ax7.axhline(y=5, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "ax7.axhline(y=-5, color='green', linestyle=':', linewidth=2, alpha=0.7)\n",
    "# Moving average\n",
    "window = max(5, len(errors) // 20)\n",
    "moving_avg = pd.Series(errors).rolling(window=window, center=True).mean()\n",
    "ax7.plot(indices, moving_avg, 'b-', linewidth=3, alpha=0.9, label=f'Moving Avg (n={window})')\n",
    "ax7.set_xlabel('Sample Index', fontsize=13, fontweight='bold')\n",
    "ax7.set_ylabel('Prediction Error (GSM)', fontsize=13, fontweight='bold')\n",
    "ax7.set_title('Sequential Error Pattern', fontsize=14, fontweight='bold')\n",
    "ax7.legend(fontsize=11)\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Q-Q Plot (Normality Check)\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "from scipy import stats\n",
    "stats.probplot(errors, dist=\"norm\", plot=ax8)\n",
    "ax8.get_lines()[0].set_markerfacecolor('blue')\n",
    "ax8.get_lines()[0].set_markeredgecolor('black')\n",
    "ax8.get_lines()[0].set_markersize(9)\n",
    "ax8.get_lines()[0].set_alpha(0.7)\n",
    "ax8.get_lines()[1].set_linewidth(3)\n",
    "ax8.get_lines()[1].set_color('red')\n",
    "ax8.set_xlabel('Theoretical Quantiles', fontsize=13, fontweight='bold')\n",
    "ax8.set_ylabel('Sample Quantiles', fontsize=13, fontweight='bold')\n",
    "ax8.set_title('Q-Q Plot (Normality Test)', fontsize=14, fontweight='bold')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Prediction confidence intervals\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "sorted_indices = np.argsort(test_actuals)\n",
    "sorted_actuals = test_actuals[sorted_indices]\n",
    "sorted_preds = test_preds[sorted_indices]\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "window_size = max(10, len(test_actuals) // 10)\n",
    "ci_upper = []\n",
    "ci_lower = []\n",
    "for i in range(len(sorted_preds)):\n",
    "    start = max(0, i - window_size // 2)\n",
    "    end = min(len(sorted_preds), i + window_size // 2)\n",
    "    local_std = np.std(sorted_preds[start:end] - sorted_actuals[start:end])\n",
    "    ci_upper.append(sorted_preds[i] + 1.96 * local_std)\n",
    "    ci_lower.append(sorted_preds[i] - 1.96 * local_std)\n",
    "\n",
    "ax9.plot(sorted_actuals, sorted_actuals, 'r--', linewidth=3, label='Perfect', zorder=5)\n",
    "ax9.plot(sorted_actuals, sorted_preds, 'bo-', linewidth=2, markersize=5, alpha=0.7, label='Predictions')\n",
    "ax9.fill_between(sorted_actuals, ci_lower, ci_upper, alpha=0.25, color='blue', label='95% CI')\n",
    "ax9.fill_between(sorted_actuals, sorted_actuals-5, sorted_actuals+5, alpha=0.12, color='green', \n",
    "                 label='¬±5 GSM')\n",
    "ax9.set_xlabel('Actual GSM (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax9.set_ylabel('Predicted GSM (g/m¬≤)', fontsize=13, fontweight='bold')\n",
    "ax9.set_title('Predictions with Confidence Intervals', fontsize=14, fontweight='bold')\n",
    "ax9.legend(fontsize=11)\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig(f'{DATASET_PATH}/comprehensive_test_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Comprehensive 9-panel test visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Predicted vs Actual scatter plot\n",
    "axes[0, 0].scatter(test_actuals, test_preds, alpha=0.6, s=50)\n",
    "axes[0, 0].plot([test_actuals.min(), test_actuals.max()], \n",
    "                [test_actuals.min(), test_actuals.max()], \n",
    "                'r--', linewidth=2, label='Perfect Prediction')\n",
    "# ¬±5 GSM bounds\n",
    "axes[0, 0].fill_between([test_actuals.min(), test_actuals.max()],\n",
    "                        [test_actuals.min()-5, test_actuals.max()-5],\n",
    "                        [test_actuals.min()+5, test_actuals.max()+5],\n",
    "                        alpha=0.2, color='green', label='¬±5 GSM')\n",
    "axes[0, 0].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 0].set_title(f'Predicted vs Actual GSM\\n(R¬≤ = {test_r2:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residual plot\n",
    "residuals = test_preds - test_actuals\n",
    "axes[0, 1].scatter(test_actuals, residuals, alpha=0.6, s=50)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].axhline(y=5, color='g', linestyle=':', linewidth=2, alpha=0.5, label='¬±5 GSM')\n",
    "axes[0, 1].axhline(y=-5, color='g', linestyle=':', linewidth=2, alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Residual (Predicted - Actual)', fontsize=12)\n",
    "axes[0, 1].set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Error distribution histogram\n",
    "axes[1, 0].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[1, 0].axvline(x=residuals.mean(), color='g', linestyle='-', linewidth=2, label=f'Mean: {residuals.mean():.2f}')\n",
    "axes[1, 0].set_xlabel('Prediction Error (GSM)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 0].set_title(f'Error Distribution\\n(MAE = {test_mae:.3f} GSM)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Absolute error vs actual GSM\n",
    "abs_errors = np.abs(residuals)\n",
    "axes[1, 1].scatter(test_actuals, abs_errors, alpha=0.6, s=50)\n",
    "axes[1, 1].axhline(y=5, color='r', linestyle='--', linewidth=2, label='¬±5 GSM Target')\n",
    "axes[1, 1].set_xlabel('Actual GSM (g/m¬≤)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Absolute Error (GSM)', fontsize=12)\n",
    "axes[1, 1].set_title('Absolute Error vs Actual GSM', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{DATASET_PATH}/prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Prediction analysis visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55bcf5",
   "metadata": {},
   "source": [
    "## 13. Save Model & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_save_path = f'{DATASET_PATH}/best_gsm_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'feature_cols': feature_cols,\n",
    "    'scaler': scaler,\n",
    "    'best_val_mae': best_val_mae,\n",
    "    'test_mae': test_mae,\n",
    "    'test_rmse': test_rmse,\n",
    "    'test_r2': test_r2,\n",
    "    'history': history\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save predictions\n",
    "results_df = df_test.copy()\n",
    "results_df['predicted_gsm'] = test_preds\n",
    "results_df['error'] = test_preds - test_actuals\n",
    "results_df['abs_error'] = np.abs(test_preds - test_actuals)\n",
    "results_df.to_csv(f'{DATASET_PATH}/test_predictions.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Predictions saved to: {DATASET_PATH}/test_predictions.csv\")\n",
    "\n",
    "# Save metrics summary\n",
    "metrics_summary = {\n",
    "    'model': 'HybridGSMPredictor (EfficientNet-B3)',\n",
    "    'total_params': total_params,\n",
    "    'trainable_params': trainable_params,\n",
    "    'num_features': len(feature_cols),\n",
    "    'train_samples': len(df_train),\n",
    "    'val_samples': len(df_val),\n",
    "    'test_samples': len(df_test),\n",
    "    'best_val_mae': float(best_val_mae),\n",
    "    'test_mae': float(test_mae),\n",
    "    'test_rmse': float(test_rmse),\n",
    "    'test_r2': float(test_r2),\n",
    "    'predictions_within_5gsm': float(within_5),\n",
    "    'predictions_within_10gsm': float(within_10),\n",
    "    'target_achieved': test_mae <= 5.0\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(f'{DATASET_PATH}/model_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Metrics saved to: {DATASET_PATH}/model_metrics.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéä ALL RESULTS SAVED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d66e01",
   "metadata": {},
   "source": [
    "## 14. Model Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea43c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gsm(model, image_path, features, scaler, device):\n",
    "    \"\"\"Predict GSM for a single image.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and transform image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features.reshape(1, -1))\n",
    "    features_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor, features_tensor)\n",
    "    \n",
    "    return prediction.item()\n",
    "\n",
    "# Test on a few samples\n",
    "print(\"\\nüìã Sample Predictions:\")\n",
    "print(\"=\"*80)\n",
    "for i in range(min(10, len(df_test))):\n",
    "    img_name = df_test.iloc[i]['image_name']\n",
    "    actual_gsm = df_test.iloc[i]['gsm']\n",
    "    img_path = os.path.join(IMAGES_PATH, img_name)\n",
    "    feats = X_test_scaled[i]\n",
    "    \n",
    "    predicted_gsm = predict_gsm(model, img_path, feats, scaler, device)\n",
    "    error = predicted_gsm - actual_gsm\n",
    "    \n",
    "    print(f\"{i+1}. {img_name}\")\n",
    "    print(f\"   Actual: {actual_gsm:.2f} GSM | Predicted: {predicted_gsm:.2f} GSM | Error: {error:+.2f} GSM\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Inference example complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae99d4c",
   "metadata": {},
   "source": [
    "## 15. Final Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüß† Model Architecture:\")\n",
    "print(f\"  - Backbone: EfficientNet-B3 (ImageNet pretrained)\")\n",
    "print(f\"  - Input: 224x224 RGB images + {len(feature_cols)} fabric features\")\n",
    "print(f\"  - Total parameters: {total_params:,}\")\n",
    "print(f\"  - Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"  - Test MAE:  {test_mae:.3f} GSM\")\n",
    "print(f\"  - Test RMSE: {test_rmse:.3f} GSM\")\n",
    "print(f\"  - Test R¬≤:   {test_r2:.4f}\")\n",
    "print(f\"  - Within ¬±5 GSM:  {within_5:.1f}%\")\n",
    "print(f\"  - Within ¬±10 GSM: {within_10:.1f}%\")\n",
    "\n",
    "print(f\"\\nüìÅ Saved Files:\")\n",
    "print(f\"  - Model: {DATASET_PATH}/best_gsm_model.pth\")\n",
    "print(f\"  - Predictions: {DATASET_PATH}/test_predictions.csv\")\n",
    "print(f\"  - Metrics: {DATASET_PATH}/model_metrics.json\")\n",
    "print(f\"  - Visualizations: {DATASET_PATH}/training_history.png\")\n",
    "print(f\"                    {DATASET_PATH}/prediction_analysis.png\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations for Further Improvement:\")\n",
    "print(f\"  1. Collect more diverse fabric samples (especially rare GSM ranges)\")\n",
    "print(f\"  2. Experiment with EfficientNet-B4/B5 for better feature extraction\")\n",
    "print(f\"  3. Add ensemble methods (combining multiple models)\")\n",
    "print(f\"  4. Fine-tune on domain-specific pretrained weights if available\")\n",
    "print(f\"  5. Implement test-time augmentation (TTA) for robustness\")\n",
    "\n",
    "if test_mae <= 5.0:\n",
    "    print(f\"\\nüéâ SUCCESS! Model achieves research-grade accuracy (¬±{test_mae:.2f} GSM)\")\n",
    "    print(f\"   This model is ready for production deployment!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Model is close but {test_mae - 5:.2f} GSM away from target\")\n",
    "    print(f\"   Consider the recommendations above for improvement.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÅ TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
