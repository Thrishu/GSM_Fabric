# Fabric GSM Prediction Pipeline Configuration
# Central hub for all hyperparameters, paths, and model settings

# ============================================================================
# DATA CONFIGURATION
# ============================================================================
data:
  # FabricNet dataset root directory (update with actual path)
  fabricnet_root: "data/FabricNet"
  
  # Image preprocessing parameters
  image_size: [224, 224]  # Resize target dimensions
  
  # Train/validation/test split ratios
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  
  # Random seed for reproducibility across splits
  random_seed: 42


# ============================================================================
# PREPROCESSING CONFIGURATION
# ============================================================================
preprocessing:
  # Histogram equalization: CLAHE (Contrast Limited Adaptive Histogram Equalization)
  enable_clahe: true
  clahe_clip_limit: 2.0
  clahe_tile_size: [8, 8]
  
  # Normalization: pixel values will be scaled to [0, 1]
  normalization: "minmax"  # Options: "minmax", "standardization"


# ============================================================================
# TEXTURE FEATURE CONFIGURATION
# ============================================================================
texture_features:
  # GLCM (Gray Level Co-occurrence Matrix)
  glcm:
    enable: true
    distances: [1, 3]  # Pixel distances to compute co-occurrence
    angles: [0, 45, 90, 135]  # Directions in degrees
    levels: 256  # Number of gray levels for quantization
    # Metrics to extract: contrast, homogeneity, energy, correlation
    metrics: ["contrast", "homogeneity", "energy", "correlation"]
  
  # Local Binary Pattern
  lbp:
    enable: true
    radius: 3  # Neighborhood radius
    n_points: 8  # Number of neighborhood points (8 * radius)
    method: "uniform"  # "uniform", "nri_uniform", or "var"
    n_bins: 59  # Number of bins for histogram (uniform LBP has 59)


# ============================================================================
# DEEP FEATURE EXTRACTION CONFIGURATION
# ============================================================================
deep_features:
  # MobileNet backbone for pretrained feature extraction
  model_type: "MobileNetV2"  # Options: "MobileNetV2", "MobileNetV3Small", "MobileNetV3Large"
  weights: "imagenet"  # Use ImageNet pretrained weights
  
  # Global average pooling compresses spatial dimensions
  pooling: "global_average"
  
  # Input normalization (ImageNet standard)
  preprocessing_mode: "tf"  # TensorFlow normalization


# ============================================================================
# FEATURE FUSION CONFIGURATION
# ============================================================================
feature_fusion:
  # Feature scaling to standardize magnitude across texture and CNN features
  scaler_type: "standard"  # Options: "standard" (z-score), "minmax"
  
  # Whether to save scaler for future inference
  save_scaler: true
  scaler_path: "models/feature_scaler.pkl"


# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
models:
  # Which regressor to use: "random_forest" or "gradient_boosting"
  active_model: "random_forest"
  
  random_forest:
    n_estimators: 100
    max_depth: 15
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42
    n_jobs: -1  # Use all available cores
    verbose: 0
  
  gradient_boosting:
    n_estimators: 100
    learning_rate: 0.1
    max_depth: 5
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42
    verbose: 0
    subsample: 0.8


# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  # Batch size for feature extraction (if processing in batches)
  batch_size: 32
  
  # Number of workers for data loading
  n_workers: 4
  
  # Whether to use GPU for deep feature extraction
  use_gpu: true


# ============================================================================
# EVALUATION CONFIGURATION
# ============================================================================
evaluation:
  # Metrics to compute: MAE, RMSE, R2
  metrics: ["mae", "rmse", "r2"]
  
  # Save predictions to CSV
  save_predictions: true
  predictions_path: "results/predictions.csv"


# ============================================================================
# OUTPUT PATHS
# ============================================================================
paths:
  # Model save locations
  models_dir: "models"
  results_dir: "results"
  logs_dir: "logs"
  
  # Final trained model
  model_save_path: "models/fabric_gsm_regressor.pkl"


# ============================================================================
# DUMMY LABELS CONFIGURATION
# ============================================================================
dummy_labels:
  # Create synthetic GSM-like values per fabric class for pipeline validation
  # Real GSM values will replace these after validation
  # Typical fabric GSM range: 50-300 g/mÂ²
  targets:
    # Format: "class_name": target_gsm_value
    # These are arbitrary but realistic values for testing
    {}  # Will be populated dynamically based on FabricNet classes
